script model/nntool_script
GEN ... /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c
python3 utils/test_accuracy_emul.py --tflite_model model/KWS_ds_cnn_m_quant.tflite --dct_coefficient_count 10 --window_size_ms 40 --window_stride_ms 20 --test_with_wav 1 --use_power_spectrogram 0
make -f emul.mk clean_model clean all DUMP_TENSORS=0 SMALL=0 MEDIUM=1 LARGE=0 WITH_MFCC=1 USE_POWER=0
make[1]: Entering directory '/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting'
script model/nntool_script
GEN ... /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c
rm -f -rf BUILD_MODEL_SQ8_EMUL
rm -f -r BUILD_EMUL
rm -f kws_ds_cnn_emul
mkdir BUILD_MODEL_SQ8_EMUL
cp model/KWS_ds_cnn_m_quant.tflite BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite
echo "GENERATING NNTOOL STATE FILE"
GENERATING NNTOOL STATE FILE
nntool -s model/nntool_script BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite -q
settings - set log level to INFO
log_level - was: 'INFO'
now: 'INFO'
open - opening graph file BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite load_quantization = True
tflite - Importing TFLITE model version 3
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
unified_quantizer - forwards SOFTMAX_0_11 in: -32.63<(i8-0.00)*0.25492236<32.38 out: None stop [] fusion False
unified_quantizer - handler SoftmaxTanHMult selected for SoftMaxParameters(SOFTMAX_0_11)
unified_quantizer - forwards in edge 0 does not match was -32.63<(i8-0.00)*0.25492236<32.38 need -64.00<(i8-0.00)*0.50000000<63.50 forced
unified_quantizer - backwards FULLY_CONNECTED_0_10 in: -9.26<(i8-0.00)*0.07232232<9.18,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced stop SOFTMAX_0_11 fusion False
unified_quantizer - handler FilterMult selected for FcParameters(FULLY_CONNECTED_0_10)
filter_mult - selecting SQ8 software kernel filter quantizer
filter_mult - node FULLY_CONNECTED_0_10 output forced to range [-64.]/[63.5] - actual range [-32.630062]/[32.375103] symmetric
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 input from c, out_cin_c, out_c to chw, out_cin_chw, out_c order - rerun adjust command
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 output from c to chw order - rerun adjust command
unified_quantizer - backwards finished in_edges FULLY_CONNECTED_0_10
unified_quantizer - backwards out edge 0 does not match was -32.63<(i8-0.00)*0.25492236<32.38 need -64.00<(i8-0.00)*0.50000000<63.50 forced
unified_quantizer - ---- STOPPED AT SOFTMAX_0_11
unified_quantizer - backwards finished out_edges FULLY_CONNECTED_0_10
unified_quantizer - forwards finished in edges SOFTMAX_0_11
unified_quantizer - forwards at SOFTMAX_0_11 on out edge 0
unified_quantizer - forwards output_1 in: -1.00<(i16-0.00)*0.00003052<1.00 out: None stop [] fusion False
unified_quantizer - handler OutputMult selected for OutputParameters(output_1)
unified_quantizer - forwards finished in edges output_1
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
debug - was: False
now: True
adjust_order - adding transposes to correct tensor order for AT kernels
set_aliases - looking for aliased edges
eliminate_transposes - eliminating unnecessary transposes
eliminate_transposes - search for transposes
eliminate_transposes - ++ Starting up from CONV_2D_0_0[1]
eliminate_transposes - looking up at DSCNNconv_1weights_quantFakeQu[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_1weights_quantFakeQu - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_0[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_0[0]
eliminate_transposes - looking down at CONV_2D_0_0_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_1 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_0[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - looking up at DSCNNconv_ds_1dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_2[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_2 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_2[1]
eliminate_transposes - looking up at DSCNNconv_ds_1pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_2[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_2[0]
eliminate_transposes - looking down at CONV_2D_0_2_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_3 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_2[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - looking up at DSCNNconv_ds_2dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_4[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_4 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_4[1]
eliminate_transposes - looking up at DSCNNconv_ds_2pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_4[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_4[0]
eliminate_transposes - looking down at CONV_2D_0_4_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_5 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_4[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - looking up at DSCNNconv_ds_3dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_6[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_6 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_6[1]
eliminate_transposes - looking up at DSCNNconv_ds_3pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_6[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_6[0]
eliminate_transposes - looking down at CONV_2D_0_6_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_7 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_6[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - looking up at DSCNNconv_ds_4dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_8[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_8 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_8[1]
eliminate_transposes - looking up at DSCNNconv_ds_4pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_8[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_8[0]
eliminate_transposes - looking down at CONV_2D_0_8_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at AVERAGE_POOL_2D_0_9[0] transpose [1, 2, 0]
eliminate_transposes - accepted AVERAGE_POOL_2D_0_9 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_8[0]
eliminate_transposes - ++ Starting down from AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - looking down at FULLY_CONNECTED_0_10[0] transpose [1, 2, 0]
eliminate_transposes - accepted FULLY_CONNECTED_0_10 - linear layer reorder input
eliminate_transposes - ++ Found results for AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - eliminate transposes
eliminate_transposes_actions - Start Action (up): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_1weights_quantFakeQu reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_1weights_quantFakeQu
eliminate_transposes_actions - Start Action (down): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_2
eliminate_transposes_actions - Start Action (up): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_4
eliminate_transposes_actions - Start Action (up): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_6
eliminate_transposes_actions - Start Action (up): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_8
eliminate_transposes_actions - Start Action (up): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose in[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - End Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - Start Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - reorder linear layer FULLY_CONNECTED_0_10 in with shape 1x1x172 transposed (2, 0, 1)
eliminate_transposes_actions - End Action (down): FULLY_CONNECTED_0_10
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - search for transposes
eliminate_transposes - no transposes to eliminate found
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - no further transpose sequences found
set_aliases - looking for aliased edges
nngraph - adjusted order
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
duplicate_operations - match_duplicate_operations does not handle quantized graphs
match_gap_conv - fusing nodes CONV_2D_0_0,CONV_2D_0_0_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_1,DEPTHWISE_CONV_2D_0_1_activation
match_gap_conv - fusing nodes CONV_2D_0_2,CONV_2D_0_2_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_3,DEPTHWISE_CONV_2D_0_3_activation
match_gap_conv - fusing nodes CONV_2D_0_4,CONV_2D_0_4_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_5,DEPTHWISE_CONV_2D_0_5_activation
match_gap_conv - fusing nodes CONV_2D_0_6,CONV_2D_0_6_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_7,DEPTHWISE_CONV_2D_0_7_activation
match_gap_conv - fusing nodes CONV_2D_0_8,CONV_2D_0_8_activation
matcher - ++ fusion fuse_gap_convs modified graph
set_aliases - looking for aliased edges
set_aliases - looking for aliased edges
duplicate_operations - match_duplicate_operations does not handle quantized graphs
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
graph_produce_node_names - was: False
now: True
graph_produce_operinfos - was: False
now: True
graph_monitor_cycles - was: False
now: True
graph_const_exec_from_flash - was: False
now: False
save_state - saved state to /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.json
echo "GENERATING AUTOTILER MODEL"
GENERATING AUTOTILER MODEL
nntool -g -M BUILD_MODEL_SQ8_EMUL -m KWS_ds_cnn_m_quantModel.c -T BUILD_MODEL_SQ8_EMUL/tensors -H KWS_ds_cnn_m_quantInfo.h  BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.json
settings - set log level to INFO
log_level - was: 'INFO'
now: 'INFO'
open - opening graph file BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite load_quantization = True
tflite - Importing TFLITE model version 3
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
unified_quantizer - forwards SOFTMAX_0_11 in: -32.63<(i8-0.00)*0.25492236<32.38 out: None stop [] fusion False
unified_quantizer - handler SoftmaxTanHMult selected for SoftMaxParameters(SOFTMAX_0_11)
unified_quantizer - forwards in edge 0 does not match was -32.63<(i8-0.00)*0.25492236<32.38 need -64.00<(i8-0.00)*0.50000000<63.50 forced
unified_quantizer - backwards FULLY_CONNECTED_0_10 in: -9.26<(i8-0.00)*0.07232232<9.18,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced stop SOFTMAX_0_11 fusion False
unified_quantizer - handler FilterMult selected for FcParameters(FULLY_CONNECTED_0_10)
filter_mult - selecting SQ8 software kernel filter quantizer
filter_mult - node FULLY_CONNECTED_0_10 output forced to range [-64.]/[63.5] - actual range [-32.630062]/[32.375103] symmetric
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 input from c, out_cin_c, out_c to chw, out_cin_chw, out_c order - rerun adjust command
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 output from c to chw order - rerun adjust command
unified_quantizer - backwards finished in_edges FULLY_CONNECTED_0_10
unified_quantizer - backwards out edge 0 does not match was -32.63<(i8-0.00)*0.25492236<32.38 need -64.00<(i8-0.00)*0.50000000<63.50 forced
unified_quantizer - ---- STOPPED AT SOFTMAX_0_11
unified_quantizer - backwards finished out_edges FULLY_CONNECTED_0_10
unified_quantizer - forwards finished in edges SOFTMAX_0_11
unified_quantizer - forwards at SOFTMAX_0_11 on out edge 0
unified_quantizer - forwards output_1 in: -1.00<(i16-0.00)*0.00003052<1.00 out: None stop [] fusion False
unified_quantizer - handler OutputMult selected for OutputParameters(output_1)
unified_quantizer - forwards finished in edges output_1
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
debug - was: False
now: True
adjust_order - adding transposes to correct tensor order for AT kernels
set_aliases - looking for aliased edges
eliminate_transposes - eliminating unnecessary transposes
eliminate_transposes - search for transposes
eliminate_transposes - ++ Starting up from CONV_2D_0_0[1]
eliminate_transposes - looking up at DSCNNconv_1weights_quantFakeQu[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_1weights_quantFakeQu - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_0[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_0[0]
eliminate_transposes - looking down at CONV_2D_0_0_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_1 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_0[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - looking up at DSCNNconv_ds_1dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_2[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_2 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_2[1]
eliminate_transposes - looking up at DSCNNconv_ds_1pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_2[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_2[0]
eliminate_transposes - looking down at CONV_2D_0_2_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_3 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_2[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - looking up at DSCNNconv_ds_2dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_4[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_4 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_4[1]
eliminate_transposes - looking up at DSCNNconv_ds_2pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_4[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_4[0]
eliminate_transposes - looking down at CONV_2D_0_4_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_5 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_4[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - looking up at DSCNNconv_ds_3dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_6[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_6 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_6[1]
eliminate_transposes - looking up at DSCNNconv_ds_3pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_6[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_6[0]
eliminate_transposes - looking down at CONV_2D_0_6_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_7 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_6[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - looking up at DSCNNconv_ds_4dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_8[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_8 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_8[1]
eliminate_transposes - looking up at DSCNNconv_ds_4pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_8[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_8[0]
eliminate_transposes - looking down at CONV_2D_0_8_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at AVERAGE_POOL_2D_0_9[0] transpose [1, 2, 0]
eliminate_transposes - accepted AVERAGE_POOL_2D_0_9 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_8[0]
eliminate_transposes - ++ Starting down from AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - looking down at FULLY_CONNECTED_0_10[0] transpose [1, 2, 0]
eliminate_transposes - accepted FULLY_CONNECTED_0_10 - linear layer reorder input
eliminate_transposes - ++ Found results for AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - eliminate transposes
eliminate_transposes_actions - Start Action (up): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_1weights_quantFakeQu reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_1weights_quantFakeQu
eliminate_transposes_actions - Start Action (down): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_2
eliminate_transposes_actions - Start Action (up): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_4
eliminate_transposes_actions - Start Action (up): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_6
eliminate_transposes_actions - Start Action (up): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_8
eliminate_transposes_actions - Start Action (up): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose in[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - End Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - Start Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - reorder linear layer FULLY_CONNECTED_0_10 in with shape 1x1x172 transposed (2, 0, 1)
eliminate_transposes_actions - End Action (down): FULLY_CONNECTED_0_10
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - search for transposes
eliminate_transposes - no transposes to eliminate found
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - no further transpose sequences found
set_aliases - looking for aliased edges
nngraph - adjusted order
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
duplicate_operations - match_duplicate_operations does not handle quantized graphs
match_gap_conv - fusing nodes CONV_2D_0_0,CONV_2D_0_0_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_1,DEPTHWISE_CONV_2D_0_1_activation
match_gap_conv - fusing nodes CONV_2D_0_2,CONV_2D_0_2_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_3,DEPTHWISE_CONV_2D_0_3_activation
match_gap_conv - fusing nodes CONV_2D_0_4,CONV_2D_0_4_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_5,DEPTHWISE_CONV_2D_0_5_activation
match_gap_conv - fusing nodes CONV_2D_0_6,CONV_2D_0_6_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_7,DEPTHWISE_CONV_2D_0_7_activation
match_gap_conv - fusing nodes CONV_2D_0_8,CONV_2D_0_8_activation
matcher - ++ fusion fuse_gap_convs modified graph
set_aliases - looking for aliased edges
set_aliases - looking for aliased edges
duplicate_operations - match_duplicate_operations does not handle quantized graphs
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
graph_produce_node_names - was: False
now: True
graph_produce_operinfos - was: False
now: True
graph_monitor_cycles - was: False
now: True
graph_const_exec_from_flash - was: False
now: False
generator - Saving model to BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantModel.c
code_generator - edge from step 1 CONV_2D_0_0_r_hwc_chw is not used and is replaced with edge from step input_1:0 0 cname: Input_1
generator - Writing constants to BUILD_MODEL_SQ8_EMUL
echo "COMPILING AUTOTILER MODEL"
COMPILING AUTOTILER MODEL
gcc -g -o BUILD_MODEL_SQ8_EMUL/GenTile -I. -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/CNN_Generators -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8 -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantModel.c /home/marco-gwt/GWT/AutotilerV2/install/lib/libtile.a -lSDL2 -lSDL2_ttf 
echo "RUNNING AUTOTILER MODEL"
RUNNING AUTOTILER MODEL
BUILD_MODEL_SQ8_EMUL/GenTile -o BUILD_MODEL_SQ8_EMUL -c BUILD_MODEL_SQ8_EMUL -f BUILD_MODEL_SQ8_EMUL --L1 48736 --L2 350000 --L3 6388608
InFeat: 1, OutFeat: 172
Conv => W:  10, Pad:[1,2] PadT:[1,2] => Wc: 10, Filter:[4,10]
     => H:  49, Pad:[4,5] PadT:[4,5] => Hc: 25
Pool => Wc: 10, Pad:[0,0] => Wo: 10, Filter:[1,1]
     => Hc: 25, Pad:[0,0] => Ho: 25
OverlapC: 8
OverlapP: 0
TileCons: 2
UsedIn  : [10 x 49]
UsedC   : [10 x 25]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConvNxMStrideSxSy_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1763000

==== Process Tiling For User Kernel:            S4_Conv2d_172x1x10x4_Relu =======================
S4_Conv2d_172x1x10x4_Relu Partition[0] Size = 194929 (Min:    200, Max: 275121), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=25
	                  In Dim:  58, TileOverlap:  8, Ratio: 2.000000
	                 Out Dim:  25, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  25, TileOverlap:  0, Ratio: 1.000000

S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: Bias, was using 704 Bytes will require 688 Bytes buffer
S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: Scale, was using 176 Bytes will require 172 Bytes buffer
S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: ScaleN, was using 176 Bytes will require 172 Bytes buffer
S4_Conv2d_172x1x10x4_Relu, TiledSpace: Tile0 Iteration Count: 4 Parametric Space: [D1, M0=88] Parametric Space: [D0, M1=1]
              In : Ratio: 2.000000, FixDim:     10, VarDim:     22 [    49], Size:    440, Total:     440, Move:       1460 (Decl x 2.979592) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:    1128, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:    1300, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:    1472, Move:        172 (Decl x 1.000000) L2
@         Filter : Ratio: 0.000000,                                          Size:   7040, Total:    8512, Move:       6880 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     10, VarDim:      7 [    25], Size:  12320, Total:   20832, Move:      43000 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:     10, VarDim:      7 [    25], Size:  24640, Total:   45472, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   45484, Move:          9 (Decl x 1.000000) L2
S4_Conv2d_172x1x10x4_Relu - IterSpace: Tile0 - L1 Memory:  45484, L2Move: 52381, L3Move: 0, Tiling Overhead: 1.018868
S4_Conv2d_172x1x10x4_Relu Partial buffering on Arg: Filter, From: D0 To: D1. Current is (Par) 1 x [W:1, H:1] x 40 => Partial buffer size is 7040 Bytes
S4_Conv2d_172x1x10x4_Relu Found Parametric value for space D1 (Initial: 172, Div: 8) = 88 [88*1 + 84] and space D0 (Initial: 1, Div: 4) = 1 [1*1 + 0], Iteration for Tiled Space: 4
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:         In, Size:    220, Base1:      0, Base2:    220
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:       Bias, Size:    688, Base1:    440, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:      Scale, Size:    172, Base1:   1128, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:     ScaleN, Size:    172, Base1:   1300, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:     Filter, Size:   3520, Base1:   1472, Base2:   4992
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:        Out, Size:   6160, Base1:   8512, Base2:  14672
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:    ConvOut, Size:  24640, Base1:  20832, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:      Infos, Size:     12, Base1:  45472, Base2:      0
S4_Conv2d_172x1x10x4_Relu For Iter Space: 0 Iteration count:   4 (Last one is truncated), Given L1 Memory:  48736, Used L1 Memory:  45484, Reusable Memory: 3252, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  10, Pad:[0,1] PadT:[0,1] => Wc: 5, Filter:[3,3]
     => H:  25, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 1
OverlapP: 0
TileCons: 2
UsedIn  : [10 x 25]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride2B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:             S7_Conv2d_172x1x3x3_Relu =======================
S7_Conv2d_172x1x3x3_Relu Partition[0] Size =  63665 (Min:     60, Max: 165257), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=13
	                  In Dim:  27, TileOverlap:  1, Ratio: 2.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 384 Bytes will require 688 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 96 Bytes will require 172 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 96 Bytes will require 172 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 864 Bytes will require 1548 Bytes buffer
S7_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=48]
              In : Ratio: 2.000000, FixDim:     10, VarDim:     25 [    25], Size:  24000, Total:   24000, Move:      43000 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   24688, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   24860, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   25032, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   26580, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:   6240, Total:   32820, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  12480, Total:   45300, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   45312, Move:          9 (Decl x 1.000000) L2
S7_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  45312, L2Move: 56769, L3Move: 0, Tiling Overhead: 1.000000
S7_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 48 [48*3 + 28], Iteration for Tiled Space: 1
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:         In, Size:  12000, Base1:      0, Base2:  12000
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  24000, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  24688, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  24860, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  25032, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   3120, Base1:  26580, Base2:  29700
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  12480, Base1:  32820, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  45300, Base2:      0
S7_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  45312, Reusable Memory: 3424, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S10_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S10_Conv2d_172x172x1x1_Relu =======================
S10_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S10_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S10_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S10_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S10_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S10_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S10_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S10_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S10_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S10_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S13_Conv2d_172x1x3x3_Relu =======================
S13_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S13_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S13_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S13_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S13_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S16_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S16_Conv2d_172x172x1x1_Relu =======================
S16_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S16_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S16_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S16_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S16_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S16_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S16_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S16_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S16_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S16_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S19_Conv2d_172x1x3x3_Relu =======================
S19_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S19_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S19_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S19_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S19_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S22_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S22_Conv2d_172x172x1x1_Relu =======================
S22_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S22_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S22_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S22_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S22_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S22_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S22_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S22_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S22_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S22_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S25_Conv2d_172x1x3x3_Relu =======================
S25_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S25_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S25_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S25_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S25_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S28_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S28_Conv2d_172x172x1x1_Relu =======================
S28_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S28_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S28_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S28_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S28_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S28_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S28_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S28_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S28_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S28_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

Pool => W: 5, Pad:[0,0] => Wo: 1
     => H: 13, Pad:[0,0] => Ho: 1
OverlapP: 11
TileCons: 2
UsedIn  : [5 x 13]
         PoolKerName: KerParPoolNxMStrideSxSy_SQ8
Nb Oper : 11180

==== Process Tiling For User Kernel:                 S29_AveragePool_13x5 =======================
S29_AveragePool_13x5 Partition[0] Size =  23063 (Min:    130, Max:  22731), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=1
	                  In Dim:  13, TileOverlap: 11, Ratio: 2.000000
	                 Out Dim:   1, TileOverlap:  0, Ratio: 1.000000

Kernel: S29_AveragePool_13x5, Total Raw Memory: 11364 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S29_AveragePool_13x5, Arg:         In, Size:  11180, Base1:      0, Base2:      0
Ker: S29_AveragePool_13x5, Arg:        Out, Size:    172, Base1:  11180, Base2:      0
Ker: S29_AveragePool_13x5, Arg:      Infos, Size:     12, Base1:  11352, Base2:      0
S29_AveragePool_13x5 For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  11364, Reusable Memory: 37372, Used L2 Memory: 0
=================================================================================================

Linear Layer S32_Linear_12x172x1x1, Linear: InDim: 172, OutDim: 12, Activation: None
Linear Kernel: KerParLinearLayerFullFeatB32_SQ8

==== Process Tiling For User Kernel:                S32_Linear_12x172x1x1 =======================
S32_Linear_12x172x1x1 Partition[0] Size =   4491 (Min:      0, Max:   4575), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=1

Kernel: S32_Linear_12x172x1x1, Total Raw Memory: 2332 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S32_Linear_12x172x1x1, Arg:         In, Size:    172, Base1:      0, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:     Filter, Size:   2064, Base1:    172, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:       Bias, Size:     48, Base1:   2236, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:        Out, Size:     12, Base1:   2284, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:      Scale, Size:     12, Base1:   2296, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:     ScaleN, Size:     12, Base1:   2308, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:      Infos, Size:     12, Base1:   2320, Base2:      0
S32_Linear_12x172x1x1 For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:   2332, Reusable Memory: 46404, Used L2 Memory: 0
=================================================================================================


==== Process Tiling For User Kernel:                          S33_SoftMax =======================
         S33_SoftMax Partition[0] Size =     51 (Min:      8, Max:     63), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=12
	                  In Dim:  12, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim:  12, TileOverlap:  0, Ratio: 1.000000

Kernel:          S33_SoftMax, Total Raw Memory: 48 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S33_SoftMax, Arg:         In, Size:     12, Base1:      0, Base2:      0
Ker: S33_SoftMax, Arg:        Out, Size:     24, Base1:     12, Base2:      0
Ker: S33_SoftMax, Arg:      Infos, Size:     12, Base1:     36, Base2:      0
         S33_SoftMax For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:     48, Reusable Memory: 48688, Used L2 Memory: 0
=================================================================================================

   Symbol:           S32_Output[   In] Adding   Edge From               S32_Linear_12x172x1x1 To                         S33_SoftMax New
   Symbol:           S29_Output[   In] Adding   Edge From                S29_AveragePool_13x5 To               S32_Linear_12x172x1x1 New
   Symbol:           S28_Output[   In] Adding   Edge From         S28_Conv2d_172x172x1x1_Relu To                S29_AveragePool_13x5 New
   Symbol:           S25_Output[   In] Adding   Edge From           S25_Conv2d_172x1x3x3_Relu To         S28_Conv2d_172x172x1x1_Relu New
   Symbol:           S22_Output[   In] Adding   Edge From         S22_Conv2d_172x172x1x1_Relu To           S25_Conv2d_172x1x3x3_Relu New
   Symbol:           S19_Output[   In] Adding   Edge From           S19_Conv2d_172x1x3x3_Relu To         S22_Conv2d_172x172x1x1_Relu New
   Symbol:           S16_Output[   In] Adding   Edge From         S16_Conv2d_172x172x1x1_Relu To           S19_Conv2d_172x1x3x3_Relu New
   Symbol:           S13_Output[   In] Adding   Edge From           S13_Conv2d_172x1x3x3_Relu To         S16_Conv2d_172x172x1x1_Relu New
   Symbol:           S10_Output[   In] Adding   Edge From         S10_Conv2d_172x172x1x1_Relu To           S13_Conv2d_172x1x3x3_Relu New
   Symbol:            S7_Output[   In] Adding   Edge From            S7_Conv2d_172x1x3x3_Relu To         S10_Conv2d_172x172x1x1_Relu New
   Symbol:            S4_Output[   In] Adding   Edge From           S4_Conv2d_172x1x10x4_Relu To            S7_Conv2d_172x1x3x3_Relu New
   Symbol:             Output_1[  Out] Adding   Edge From                         S33_SoftMax To                       __GraphExit__ New
   Symbol:            S33_Infos[   In] Adding   Edge From                      __GraphEntry__ To                         S33_SoftMax New
   Symbol:            S32_Infos[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 New
   Symbol:        S32_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:        S32_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:  Dscnnfc1matmul_bias[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol: Dscnnfc1weights_quantfakequant[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:            S29_Infos[   In] Adding   Edge From                      __GraphEntry__ To                S29_AveragePool_13x5 New
   Symbol:            S28_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu New
   Symbol:        S28_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S28_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_4pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_4pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S25_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu New
   Symbol:        S25_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S25_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_4dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_4dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S22_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu New
   Symbol:        S22_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S22_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_3pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_3pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S19_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu New
   Symbol:        S19_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S19_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_3dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_3dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S16_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu New
   Symbol:        S16_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S16_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_2pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_2pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S13_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu New
   Symbol:        S13_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S13_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_2dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_2dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S10_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu New
   Symbol:        S10_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S10_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_1pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_1pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol:             S7_Infos[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu New
   Symbol:         S7_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol:         S7_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_1dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_1dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol:             S4_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu New
   Symbol:         S4_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol:         S4_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol: Dscnnconv_1conv2d_fold_bias[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol: Dscnnconv_1weights_quantfakequ[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol:              Input_1[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
After Dynamic Allocation, TopL3: 0, TopL2: 54180 => Alloc: OK

After Const Allocation, TopL3: 0, TopL2: 197153 => Alloc: OK

[FULL] Remapping [54180 .. 197152] to [0 .. 142972] Align compensation: 3
[PART] Remapping [0 .. 54179] to [142976 .. 197155] Align compensation: 0
[PART] Remapping [197153 .. 349999] to [197156 .. 350002] Align compensation: 1
Symbol allocation for graph KWS_ds_cnn_m_quantCNN is sucessfull, L2: 197153 out of 350000, L3: 0 out of 6388608
------------------------------------------------------------------------------------------------------------------------------------------------
Graph structure:

Node   0, Channel   0  0: GraphEntry __GraphEntry__, Operations: 0
                                   (null) =>                        Input_1
                                   (null) => Dscnnconv_1weights_quantfakequ
                                   (null) =>    Dscnnconv_1conv2d_fold_bias
                                   (null) =>                   S4_Mul_scale
                                   (null) =>                   S4_Mul_shift
                                   (null) =>                       S4_Infos
                                   (null) => Dscnnconv_ds_1dw_convweights_q
                                   (null) => Dscnnconv_ds_1dw_convdepthwise
                                   (null) =>                   S7_Mul_scale
                                   (null) =>                   S7_Mul_shift
                                   (null) =>                       S7_Infos
                                   (null) => Dscnnconv_ds_1pw_convweights_q
                                   (null) => Dscnnconv_ds_1pw_convconv2d_fo
                                   (null) =>                  S10_Mul_scale
                                   (null) =>                  S10_Mul_shift
                                   (null) =>                      S10_Infos
                                   (null) => Dscnnconv_ds_2dw_convweights_q
                                   (null) => Dscnnconv_ds_2dw_convdepthwise
                                   (null) =>                  S13_Mul_scale
                                   (null) =>                  S13_Mul_shift
                                   (null) =>                      S13_Infos
                                   (null) => Dscnnconv_ds_2pw_convweights_q
                                   (null) => Dscnnconv_ds_2pw_convconv2d_fo
                                   (null) =>                  S16_Mul_scale
                                   (null) =>                  S16_Mul_shift
                                   (null) =>                      S16_Infos
                                   (null) => Dscnnconv_ds_3dw_convweights_q
                                   (null) => Dscnnconv_ds_3dw_convdepthwise
                                   (null) =>                  S19_Mul_scale
                                   (null) =>                  S19_Mul_shift
                                   (null) =>                      S19_Infos
                                   (null) => Dscnnconv_ds_3pw_convweights_q
                                   (null) => Dscnnconv_ds_3pw_convconv2d_fo
                                   (null) =>                  S22_Mul_scale
                                   (null) =>                  S22_Mul_shift
                                   (null) =>                      S22_Infos
                                   (null) => Dscnnconv_ds_4dw_convweights_q
                                   (null) => Dscnnconv_ds_4dw_convdepthwise
                                   (null) =>                  S25_Mul_scale
                                   (null) =>                  S25_Mul_shift
                                   (null) =>                      S25_Infos
                                   (null) => Dscnnconv_ds_4pw_convweights_q
                                   (null) => Dscnnconv_ds_4pw_convconv2d_fo
                                   (null) =>                  S28_Mul_scale
                                   (null) =>                  S28_Mul_shift
                                   (null) =>                      S28_Infos
                                   (null) =>                      S29_Infos
                                   (null) => Dscnnfc1weights_quantfakequant
                                   (null) =>            Dscnnfc1matmul_bias
                                   (null) =>                  S32_Mul_scale
                                   (null) =>                  S32_Mul_shift
                                   (null) =>                      S32_Infos
                                   (null) =>                      S33_Infos
	Kernel Memory      : L3:       0, L2:       0
	Kernel Total Memory:       0, L3 moves:       0, L2 moves:       0, Move overhead: 1.000000
	Kernel Operations  :       0 [KernelOper/GraphOper: 0.000000%], Move/Operation ratio: [L3: 0.000000, L2: 0.000000]
	Successors:  2 1 3 4 5 6 7 8 9 10 11 12

    Living Dynamic Symbols: [Input_1] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   1, Channel   1  1:       UKer S4_Conv2d_172x1x10x4_Relu, Operations: 1763000
 I                                     In =>                        Input_1    --L2--    Size:     490, L3_Move:         0, L2_Move:      1460, TileOverhead: 2.979592, L2Buff:     0, Addr: 0
CI PartBuff                        Filter => Dscnnconv_1weights_quantfakequ    --L2--    Size:    6880, L3_Move:         0, L2_Move:      6880, TileOverhead: 1.000000, L2Buff:     0, Addr: 1472
CI Buff                              Bias =>    Dscnnconv_1conv2d_fold_bias    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 440
 O                                    Out =>                      S4_Output    --L2--    Size:   43000, L3_Move:         0, L2_Move:     43000, TileOverhead: 1.000000, L2Buff:     0, Addr: 8512
CI Buff                             Scale =>                   S4_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 1128
CI Buff                            ScaleN =>                   S4_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 1300
CI Buff                             Infos =>                       S4_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45472
	Kernel Memory      : L3:       0, L2:   51411
	Kernel Total Memory:   51411, L3 moves:       0, L2 moves:   52381, Move overhead: 1.018868
	Kernel Operations  : 1763000 [KernelOper/GraphOper: 17.780609%], Move/Operation ratio: [L3: 0.000000, L2: 0.029711]
	Successors:  2

    Living Dynamic Symbols: [Input_1] [S4_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   2, Channel   0  0:       UKer S7_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                      S4_Output    --L2--    Size:   43000, L3_Move:         0, L2_Move:     43000, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_1dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 25032
CI Buff                              Bias => Dscnnconv_ds_1dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 24000
 O                                    Out =>                      S7_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26580
CI Buff                             Scale =>                   S7_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 24688
CI Buff                            ScaleN =>                   S7_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 24860
CI Buff                             Infos =>                       S7_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45300
	Kernel Memory      : L3:       0, L2:   56769
	Kernel Total Memory:   56769, L3 moves:       0, L2 moves:   56769, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.507773]
	Successors:  3

    Living Dynamic Symbols: [S4_Output] [S7_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   3, Channel   0  0:       UKer S10_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                      S7_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_1pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_1pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S10_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S10_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S10_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S10_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  4

    Living Dynamic Symbols: [S7_Output] [S10_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   4, Channel   0  0:       UKer S13_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S10_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_2dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_2dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S13_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S13_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S13_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S13_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  5

    Living Dynamic Symbols: [S10_Output] [S13_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   5, Channel   0  0:       UKer S16_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S13_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_2pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_2pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S16_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S16_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S16_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S16_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  6

    Living Dynamic Symbols: [S13_Output] [S16_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   6, Channel   0  0:       UKer S19_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S16_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_3dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_3dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S19_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S19_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S19_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S19_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  7

    Living Dynamic Symbols: [S16_Output] [S19_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   7, Channel   0  0:       UKer S22_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S19_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_3pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_3pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S22_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S22_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S22_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S22_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  8

    Living Dynamic Symbols: [S19_Output] [S22_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   8, Channel   0  0:       UKer S25_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S22_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_4dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_4dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S25_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S25_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S25_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S25_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  9

    Living Dynamic Symbols: [S22_Output] [S25_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   9, Channel   0  0:       UKer S28_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S25_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_4pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_4pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S28_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S28_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S28_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S28_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  10

    Living Dynamic Symbols: [S25_Output] [S28_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  10, Channel   0  0:       UKer S29_AveragePool_13x5, Operations: 11180
 I Buff                                In =>                     S28_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
 O Buff                               Out =>                     S29_Output    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11180
CI Buff                             Infos =>                      S29_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 11352
	Kernel Memory      : L3:       0, L2:   11361
	Kernel Total Memory:   11361, L3 moves:       0, L2 moves:   11361, Move overhead: 1.000000
	Kernel Operations  :   11180 [KernelOper/GraphOper: 0.112755%], Move/Operation ratio: [L3: 0.000000, L2: 1.016190]
	Successors:  11

    Living Dynamic Symbols: [S28_Output] [S29_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  11, Channel   0  0:       UKer S32_Linear_12x172x1x1, Operations: 2064
 I Buff                                In =>                     S29_Output    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnfc1weights_quantfakequant    --L2--    Size:    2064, L3_Move:         0, L2_Move:      2064, TileOverhead: 1.000000, L2Buff:     0, Addr: 172
CI Buff                              Bias =>            Dscnnfc1matmul_bias    --L2--    Size:      48, L3_Move:         0, L2_Move:        48, TileOverhead: 1.000000, L2Buff:     0, Addr: 2236
 O Buff                               Out =>                     S32_Output    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2284
CI Buff                             Scale =>                  S32_Mul_scale    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2296
CI Buff                            ScaleN =>                  S32_Mul_shift    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2308
CI Buff                             Infos =>                      S32_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 2320
	Kernel Memory      : L3:       0, L2:    2329
	Kernel Total Memory:    2329, L3 moves:       0, L2 moves:    2329, Move overhead: 1.000000
	Kernel Operations  :    2064 [KernelOper/GraphOper: 0.020816%], Move/Operation ratio: [L3: 0.000000, L2: 1.128392]
	Successors:  12

    Living Dynamic Symbols: [S29_Output] [S32_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  12, Channel   0  0:       UKer S33_SoftMax, Operations: 12
 I Buff                                In =>                     S32_Output    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
 O Buff                               Out =>                       Output_1    --L2--    Size:      24, L3_Move:         0, L2_Move:        24, TileOverhead: 1.000000, L2Buff:     0, Addr: 12
CI Buff                             Infos =>                      S33_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 36
	Kernel Memory      : L3:       0, L2:      45
	Kernel Total Memory:      45, L3 moves:       0, L2 moves:      45, Move overhead: 1.000000
	Kernel Operations  :      12 [KernelOper/GraphOper: 0.000121%], Move/Operation ratio: [L3: 0.000000, L2: 3.750000]
	Successors:  13

    Living Dynamic Symbols: [Output_1] [S32_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  13, Channel   0  0:  GraphExit __GraphExit__, Operations: 0
                                   (null) =>                       Output_1
	Kernel Memory      : L3:       0, L2:       0
	Kernel Total Memory:       0, L3 moves:       0, L2 moves:       0, Move overhead: 1.000000
	Kernel Operations  :       0 [KernelOper/GraphOper: 0.000000%], Move/Operation ratio: [L3: 0.000000, L2: 0.000000]
	Successors: 

    Living Dynamic Symbols: [Output_1] 

------------------------------------------------------------------------------------------------------------------------------------------------
	Graph nodes max local memory : L3:       0, L2:   56769
	Graph nodes min global memory: L3:       0, L2:   56772
	Graph sum of kernel arguments size:  408702, L3 moves:       0, L2 moves:  499112, Move overhead: 1.221213
	Graph total operations: 9915296


------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Memory bandwidth report:

    Sum of All Kernel's arguments size:  408702, Total L3_Move:         0, Total L2_Move:    499112, Tiling Overhead Average: 1.221213

------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Total minimum memory requirement report:

                     L3 Memory       L2 Memory
       Dynamic               0           54180
         Const               0           30628
         Total               0           56772
------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Graph symbols allocation:

              Input_1  Externally allocated
 Dscnnconv_1weights_quantfakequ  INSTALL: HyperFlash[  0: 13]@ 118336    LOAD:         L2[  0: 13]@ 118336    EXEC:         L2[  0: 13]@ 118336 , Size:    6880
 Dscnnconv_1conv2d_fold_bias  INSTALL: HyperFlash[  0: 13]@ 133472    LOAD:         L2[  0: 13]@ 133472    EXEC:         L2[  0: 13]@ 133472 , Size:     688
         S4_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 139664    LOAD:         L2[  0: 13]@ 139664    EXEC:         L2[  0: 13]@ 139664 , Size:     172
         S4_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 139836    LOAD:         L2[  0: 13]@ 139836    EXEC:         L2[  0: 13]@ 139836 , Size:     172
             S4_Infos  INSTALL: HyperFlash[  0: 13]@ 142808    LOAD:         L2[  0: 13]@ 142808    EXEC:         L2[  0: 13]@ 142808 , Size:       9
 Dscnnconv_ds_1dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 127280    LOAD:         L2[  0: 13]@ 127280    EXEC:         L2[  0: 13]@ 127280 , Size:    1548
 Dscnnconv_ds_1dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 134160    LOAD:         L2[  0: 13]@ 134160    EXEC:         L2[  0: 13]@ 134160 , Size:     688
         S7_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140008    LOAD:         L2[  0: 13]@ 140008    EXEC:         L2[  0: 13]@ 140008 , Size:     172
         S7_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140180    LOAD:         L2[  0: 13]@ 140180    EXEC:         L2[  0: 13]@ 140180 , Size:     172
             S7_Infos  INSTALL: HyperFlash[  0: 13]@ 142820    LOAD:         L2[  0: 13]@ 142820    EXEC:         L2[  0: 13]@ 142820 , Size:       9
 Dscnnconv_ds_1pw_convweights_q  INSTALL: HyperFlash[  0: 13]@      0    LOAD:         L2[  0: 13]@      0    EXEC:         L2[  0: 13]@      0 , Size:   29584
 Dscnnconv_ds_1pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 134848    LOAD:         L2[  0: 13]@ 134848    EXEC:         L2[  0: 13]@ 134848 , Size:     688
        S10_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140352    LOAD:         L2[  0: 13]@ 140352    EXEC:         L2[  0: 13]@ 140352 , Size:     172
        S10_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140524    LOAD:         L2[  0: 13]@ 140524    EXEC:         L2[  0: 13]@ 140524 , Size:     172
            S10_Infos  INSTALL: HyperFlash[  0: 13]@ 142832    LOAD:         L2[  0: 13]@ 142832    EXEC:         L2[  0: 13]@ 142832 , Size:       9
 Dscnnconv_ds_2dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 128828    LOAD:         L2[  0: 13]@ 128828    EXEC:         L2[  0: 13]@ 128828 , Size:    1548
 Dscnnconv_ds_2dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 135536    LOAD:         L2[  0: 13]@ 135536    EXEC:         L2[  0: 13]@ 135536 , Size:     688
        S13_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140696    LOAD:         L2[  0: 13]@ 140696    EXEC:         L2[  0: 13]@ 140696 , Size:     172
        S13_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140868    LOAD:         L2[  0: 13]@ 140868    EXEC:         L2[  0: 13]@ 140868 , Size:     172
            S13_Infos  INSTALL: HyperFlash[  0: 13]@ 142844    LOAD:         L2[  0: 13]@ 142844    EXEC:         L2[  0: 13]@ 142844 , Size:       9
 Dscnnconv_ds_2pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  29584    LOAD:         L2[  0: 13]@  29584    EXEC:         L2[  0: 13]@  29584 , Size:   29584
 Dscnnconv_ds_2pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 136224    LOAD:         L2[  0: 13]@ 136224    EXEC:         L2[  0: 13]@ 136224 , Size:     688
        S16_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141040    LOAD:         L2[  0: 13]@ 141040    EXEC:         L2[  0: 13]@ 141040 , Size:     172
        S16_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141212    LOAD:         L2[  0: 13]@ 141212    EXEC:         L2[  0: 13]@ 141212 , Size:     172
            S16_Infos  INSTALL: HyperFlash[  0: 13]@ 142856    LOAD:         L2[  0: 13]@ 142856    EXEC:         L2[  0: 13]@ 142856 , Size:       9
 Dscnnconv_ds_3dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 130376    LOAD:         L2[  0: 13]@ 130376    EXEC:         L2[  0: 13]@ 130376 , Size:    1548
 Dscnnconv_ds_3dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 136912    LOAD:         L2[  0: 13]@ 136912    EXEC:         L2[  0: 13]@ 136912 , Size:     688
        S19_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141384    LOAD:         L2[  0: 13]@ 141384    EXEC:         L2[  0: 13]@ 141384 , Size:     172
        S19_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141556    LOAD:         L2[  0: 13]@ 141556    EXEC:         L2[  0: 13]@ 141556 , Size:     172
            S19_Infos  INSTALL: HyperFlash[  0: 13]@ 142868    LOAD:         L2[  0: 13]@ 142868    EXEC:         L2[  0: 13]@ 142868 , Size:       9
 Dscnnconv_ds_3pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  59168    LOAD:         L2[  0: 13]@  59168    EXEC:         L2[  0: 13]@  59168 , Size:   29584
 Dscnnconv_ds_3pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 137600    LOAD:         L2[  0: 13]@ 137600    EXEC:         L2[  0: 13]@ 137600 , Size:     688
        S22_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141728    LOAD:         L2[  0: 13]@ 141728    EXEC:         L2[  0: 13]@ 141728 , Size:     172
        S22_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141900    LOAD:         L2[  0: 13]@ 141900    EXEC:         L2[  0: 13]@ 141900 , Size:     172
            S22_Infos  INSTALL: HyperFlash[  0: 13]@ 142880    LOAD:         L2[  0: 13]@ 142880    EXEC:         L2[  0: 13]@ 142880 , Size:       9
 Dscnnconv_ds_4dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 131924    LOAD:         L2[  0: 13]@ 131924    EXEC:         L2[  0: 13]@ 131924 , Size:    1548
 Dscnnconv_ds_4dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 138288    LOAD:         L2[  0: 13]@ 138288    EXEC:         L2[  0: 13]@ 138288 , Size:     688
        S25_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142072    LOAD:         L2[  0: 13]@ 142072    EXEC:         L2[  0: 13]@ 142072 , Size:     172
        S25_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142244    LOAD:         L2[  0: 13]@ 142244    EXEC:         L2[  0: 13]@ 142244 , Size:     172
            S25_Infos  INSTALL: HyperFlash[  0: 13]@ 142892    LOAD:         L2[  0: 13]@ 142892    EXEC:         L2[  0: 13]@ 142892 , Size:       9
 Dscnnconv_ds_4pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  88752    LOAD:         L2[  0: 13]@  88752    EXEC:         L2[  0: 13]@  88752 , Size:   29584
 Dscnnconv_ds_4pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 138976    LOAD:         L2[  0: 13]@ 138976    EXEC:         L2[  0: 13]@ 138976 , Size:     688
        S28_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142416    LOAD:         L2[  0: 13]@ 142416    EXEC:         L2[  0: 13]@ 142416 , Size:     172
        S28_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142588    LOAD:         L2[  0: 13]@ 142588    EXEC:         L2[  0: 13]@ 142588 , Size:     172
            S28_Infos  INSTALL: HyperFlash[  0: 13]@ 142904    LOAD:         L2[  0: 13]@ 142904    EXEC:         L2[  0: 13]@ 142904 , Size:       9
            S29_Infos  INSTALL: HyperFlash[  0: 13]@ 142916    LOAD:         L2[  0: 13]@ 142916    EXEC:         L2[  0: 13]@ 142916 , Size:       9
 Dscnnfc1weights_quantfakequant  INSTALL: HyperFlash[  0: 13]@ 125216    LOAD:         L2[  0: 13]@ 125216    EXEC:         L2[  0: 13]@ 125216 , Size:    2064
  Dscnnfc1matmul_bias  INSTALL: HyperFlash[  0: 13]@ 142760    LOAD:         L2[  0: 13]@ 142760    EXEC:         L2[  0: 13]@ 142760 , Size:      48
        S32_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142928    LOAD:         L2[  0: 13]@ 142928    EXEC:         L2[  0: 13]@ 142928 , Size:      12
        S32_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142940    LOAD:         L2[  0: 13]@ 142940    EXEC:         L2[  0: 13]@ 142940 , Size:      12
            S32_Infos  INSTALL: HyperFlash[  0: 13]@ 142952    LOAD:         L2[  0: 13]@ 142952    EXEC:         L2[  0: 13]@ 142952 , Size:       9
            S33_Infos  INSTALL: HyperFlash[  0: 13]@ 142964    LOAD:         L2[  0: 13]@ 142964    EXEC:         L2[  0: 13]@ 142964 , Size:       9
             Output_1  Externally allocated
            S4_Output     EXEC:         L2[  1:  2]@ 154156 , Size:   43000
            S7_Output     EXEC:         L2[  2:  3]@ 142976 , Size:   11180
           S10_Output     EXEC:         L2[  3:  4]@ 154156 , Size:   11180
           S13_Output     EXEC:         L2[  4:  5]@ 142976 , Size:   11180
           S16_Output     EXEC:         L2[  5:  6]@ 154156 , Size:   11180
           S19_Output     EXEC:         L2[  6:  7]@ 142976 , Size:   11180
           S22_Output     EXEC:         L2[  7:  8]@ 154156 , Size:   11180
           S25_Output     EXEC:         L2[  8:  9]@ 165336 , Size:   11180
           S28_Output     EXEC:         L2[  9: 10]@ 142976 , Size:   11180
           S29_Output     EXEC:         L2[ 10: 11]@ 154156 , Size:     172
           S32_Output     EXEC:         L2[ 11: 12]@ 142976 , Size:      12
------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Graph stacked tensors
------------------------------------------------------------------------------------------------------------------------------------------------

Generating Code For User Kernel:           S4_Conv2d_172x1x10x4_Relu
Generating Code For User Kernel:            S7_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S10_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S13_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S16_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S19_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S22_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S25_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S28_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:                S29_AveragePool_13x5
Generating Code For User Kernel:               S32_Linear_12x172x1x1
Generating Code For User Kernel:                         S33_SoftMax
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_1weights_quantfakequ.tensor: 6880 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_1conv2d_fold_bias.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S29_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnfc1weights_quantfakequant.tensor: 2064 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnfc1matmul_bias.tensor: 12 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Mul_scale.tensor: 12 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Mul_shift.tensor: 12 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S33_Infos.tensor: 9 Byte items
Flash image KWS_ds_cnn_m_quant_L3_Flash_Const.dat (size 142976) for device AT_MEM_L3_HFLASH successfuly generated

Shared L1 Memory size (Bytes)             : Given:      48736, Used:      45492
L2 Memory size (Bytes)                    : Given:     350000, Used:     197153
L3 Memory size (Bytes)                    : Given:    6388608, Used:          0

L3 Memory bandwidth for 1 graph run       :          0 Bytes
L2 Memory bandwidth for 1 graph run       :     499112 Bytes
Sum of all Kernels arguments size         :     408702 Bytes
Tiling Bandwith overhead                  :   1.221213 Move/KerArgSize
Sum of baseline bandwidth                 :   15711780 Bytes
Percentage of baseline BW for L2          :    3.17667 %
Percentage of baseline BW for L3          :          0 %
Sum of all Kernels operations             :    9915296 Operations
Total amount of flash coefficients        :     142976 Bytes

Basic kernels library                     : CNN_BasicKernels_SQ8.h
                                          : KWS_ds_cnn_m_quant.h
Output Directory                          : BUILD_MODEL_SQ8_EMUL

The following files have been generated:
	   KWS_ds_cnn_m_quantKernels.c Generated C code for the user kernels and the user kernels groups
	   KWS_ds_cnn_m_quantKernels.h Header file for the generated C code
	KWS_ds_cnn_m_quant_L3_Flash_Const.dat Flash content for Graph constants
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c main_emulation.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL/main_emulation.d -o BUILD_EMUL/main_emulation.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.d -o BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.d -o BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.d -o BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.o
gcc -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -MMD -MP -DMEDIUM -DWITH_MFCC -g -O0 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -o kws_ds_cnn_emul  BUILD_EMUL/main_emulation.o  BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.o  BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.o  BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.o  -lm
make[1]: Leaving directory '/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting'
{'desired_samples': 16000, 'window_size_samples': 640, 'window_stride_samples': 320, 'spectrogram_length': 49, 'dct_coefficient_count': 10, 'fingerprint_width': 10, 'fingerprint_size': 490, 'label_count': 12, 'sample_rate': 16000, 'preprocess': 'mfcc', 'average_window_width': -1, 'use_power': False}
Pred/Tot:	  92/ 100	Accuracy:	92.00%
Pred/Tot:	 189/ 200	Accuracy:	94.50%
Pred/Tot:	 281/ 300	Accuracy:	93.67%
Pred/Tot:	 373/ 400	Accuracy:	93.25%
Pred/Tot:	 469/ 500	Accuracy:	93.80%
Pred/Tot:	 559/ 600	Accuracy:	93.17%
Pred/Tot:	 652/ 700	Accuracy:	93.14%
Pred/Tot:	 744/ 800	Accuracy:	93.00%
Pred/Tot:	 837/ 900	Accuracy:	93.00%
Pred/Tot:	 934/1000	Accuracy:	93.40%
Pred/Tot:	1029/1100	Accuracy:	93.55%
Pred/Tot:	1119/1200	Accuracy:	93.25%
Pred/Tot:	1206/1300	Accuracy:	92.77%
Pred/Tot:	1298/1400	Accuracy:	92.71%
Pred/Tot:	1386/1500	Accuracy:	92.40%
Pred/Tot:	1483/1600	Accuracy:	92.69%
Pred/Tot:	1575/1700	Accuracy:	92.65%
Pred/Tot:	1668/1800	Accuracy:	92.67%
Pred/Tot:	1762/1900	Accuracy:	92.74%
Pred/Tot:	1856/2000	Accuracy:	92.80%
Pred/Tot:	1948/2100	Accuracy:	92.76%
Pred/Tot:	2042/2200	Accuracy:	92.82%
Pred/Tot:	2132/2300	Accuracy:	92.70%
Pred/Tot:	2222/2400	Accuracy:	92.58%
Pred/Tot:	2310/2500	Accuracy:	92.40%
Pred/Tot:	2402/2600	Accuracy:	92.38%
Pred/Tot:	2496/2700	Accuracy:	92.44%
Pred/Tot:	2587/2800	Accuracy:	92.39%
Pred/Tot:	2679/2900	Accuracy:	92.38%
Pred/Tot:	2767/3000	Accuracy:	92.23%
Pred/Tot:	2862/3100	Accuracy:	92.32%
Pred/Tot:	2956/3200	Accuracy:	92.38%
Pred/Tot:	3051/3300	Accuracy:	92.45%
Pred/Tot:	3140/3400	Accuracy:	92.35%
Pred/Tot:	3230/3500	Accuracy:	92.29%
Pred/Tot:	3323/3600	Accuracy:	92.31%
Pred/Tot:	3414/3700	Accuracy:	92.27%
Pred/Tot:	3510/3800	Accuracy:	92.37%
Pred/Tot:	3604/3900	Accuracy:	92.41%
Pred/Tot:	3699/4000	Accuracy:	92.47%
Pred/Tot:	3793/4100	Accuracy:	92.51%
Pred/Tot:	3886/4200	Accuracy:	92.52%
Pred/Tot:	3982/4300	Accuracy:	92.60%
Pred/Tot:	4074/4400	Accuracy:	92.59%

FINAL VALIDATION ACCURACY:
Pred/Tot:	4116/4444	Accuracy:	92.62%

Confusion matrix:
[[371   0   0   0   0   0   0   0   0   0   0   0]
 [  0 301   8   4   7   9   5  12   8   1   4  12]
 [  0   2 390   0   0   1   0   0   0   0   0   4]
 [  0   6   2 363   0   6   0   0   0   1   2  26]
 [  0   2   1   0 325   1   5   0   1   4   8   3]
 [  0   6   2   8   1 348   1   0   0   1   2   8]
 [  0   2  11   2   0   0 333   2   0   2   0   0]
 [  0   6   2   1   0   1   3 350   0   0   0   0]
 [  1   5   0   1   4   1   0   0 333  10   1   7]
 [  0   1   0   2  32   1   2   1   4 323   2   5]
 [  1   0   1   0  11   4   0   0   1   1 330   1]
 [  0   4   0   8   1   6   0   0   1   0   3 349]]
Pred/Tot:	  92/ 100	Accuracy:	92.00%
Pred/Tot:	 185/ 200	Accuracy:	92.50%
Pred/Tot:	 276/ 300	Accuracy:	92.00%
Pred/Tot:	 367/ 400	Accuracy:	91.75%
Pred/Tot:	 457/ 500	Accuracy:	91.40%
Pred/Tot:	 550/ 600	Accuracy:	91.67%
Pred/Tot:	 645/ 700	Accuracy:	92.14%
Pred/Tot:	 738/ 800	Accuracy:	92.25%
Pred/Tot:	 832/ 900	Accuracy:	92.44%
Pred/Tot:	 924/1000	Accuracy:	92.40%
Pred/Tot:	1015/1100	Accuracy:	92.27%
Pred/Tot:	1108/1200	Accuracy:	92.33%
Pred/Tot:	1197/1300	Accuracy:	92.08%
Pred/Tot:	1291/1400	Accuracy:	92.21%
Pred/Tot:	1383/1500	Accuracy:	92.20%
Pred/Tot:	1477/1600	Accuracy:	92.31%
Pred/Tot:	1572/1700	Accuracy:	92.47%
Pred/Tot:	1667/1800	Accuracy:	92.61%
Pred/Tot:	1758/1900	Accuracy:	92.53%
Pred/Tot:	1849/2000	Accuracy:	92.45%
Pred/Tot:	1940/2100	Accuracy:	92.38%
Pred/Tot:	2034/2200	Accuracy:	92.45%
Pred/Tot:	2127/2300	Accuracy:	92.48%
Pred/Tot:	2215/2400	Accuracy:	92.29%
Pred/Tot:	2308/2500	Accuracy:	92.32%
Pred/Tot:	2400/2600	Accuracy:	92.31%
Pred/Tot:	2493/2700	Accuracy:	92.33%
Pred/Tot:	2585/2800	Accuracy:	92.32%
Pred/Tot:	2672/2900	Accuracy:	92.14%
Pred/Tot:	2764/3000	Accuracy:	92.13%
Pred/Tot:	2853/3100	Accuracy:	92.03%
Pred/Tot:	2947/3200	Accuracy:	92.09%
Pred/Tot:	3045/3300	Accuracy:	92.27%
Pred/Tot:	3141/3400	Accuracy:	92.38%
Pred/Tot:	3234/3500	Accuracy:	92.40%
Pred/Tot:	3330/3600	Accuracy:	92.50%
Pred/Tot:	3423/3700	Accuracy:	92.51%
Pred/Tot:	3515/3800	Accuracy:	92.50%
Pred/Tot:	3610/3900	Accuracy:	92.56%
Pred/Tot:	3701/4000	Accuracy:	92.53%
Pred/Tot:	3794/4100	Accuracy:	92.54%
Pred/Tot:	3887/4200	Accuracy:	92.55%
Pred/Tot:	3984/4300	Accuracy:	92.65%
Pred/Tot:	4073/4400	Accuracy:	92.57%
Pred/Tot:	4168/4500	Accuracy:	92.62%
Pred/Tot:	4254/4600	Accuracy:	92.48%
Pred/Tot:	4344/4700	Accuracy:	92.43%
Pred/Tot:	4438/4800	Accuracy:	92.46%

FINAL TESTING ACCURACY:
Pred/Tot:	4520/4889	Accuracy:	92.45%

Confusion matrix:
[[408   0   0   0   0   0   0   0   0   0   0   0]
 [  0 339   2   6   4  11   7  12   5   2   9  11]
 [  0   3 411   0   2   0   1   0   0   0   0   2]
 [  0   4   5 358   1  16   0   0   0   0   0  21]
 [  0   5   0   0 397   3   0   1   4   3   8   4]
 [  0   4   3  10   0 375   3   0   0   0   3   8]
 [  0   0  11   3   0   0 392   5   0   0   1   0]
 [  0  11   0   0   0   1   4 379   0   0   1   0]
 [  0   8   0   0   6   5   0   0 355   8   1  13]
 [  0   3   0   1  27   2   0   1   7 343   2  16]
 [  0   4   0   0   7   3   0   1   0   0 389   7]
 [  0   3   1  13   3   5   2   0   0   0   1 374]]
