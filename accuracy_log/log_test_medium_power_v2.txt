script model/nntool_script
GEN ... /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c
python3 utils/test_accuracy_emul.py --tflite_model model/KWS_ds_cnn_m_quant_power.tflite --dct_coefficient_count 10 --window_size_ms 40 --window_stride_ms 20 --test_with_wav 1 --use_power_spectrogram 1
WARNING:tensorflow:From utils/test_accuracy_emul.py:311: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from main_emulation.c:32:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:46:20: warning: useless storage class specifier in empty declaration
   46 |     typedef struct pi_device {};
      |                    ^~~~~~~~~
In file included from /home/marco-gwt/GWT/AutotilerV2/Emulation/at_api.h:21,
                 from /home/marco-gwt/GWT/AutotilerV2/Emulation/Gap.h:18,
                 from /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_BasicKernels_SQ8.h:3,
                 from BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.h:5,
                 from BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.c:1:
/home/marco-gwt/GWT/AutotilerV2/Emulation/at_api_emul.h: In function ‘__at_hyperflash_fs_copy’:
/home/marco-gwt/GWT/AutotilerV2/Emulation/at_api_emul.h:173:8: warning: ignoring return value of ‘fread’, declared with attribute warn_unused_result [-Wunused-result]
  173 |   else fread(loc, 1, size, file);
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:46:20: warning: useless storage class specifier in empty declaration
   46 |     typedef struct pi_device {};
      |                    ^~~~~~~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c: In function ‘WritePPMHeader’:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:404:17: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  404 |         __WRITE(FD,&(Buffer[a]), sizeof(unsigned char));
      |                 ^~
      |                 |
      |                 void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c: In function ‘WriteImageToFile’:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:37:57: warning: initialization of ‘void *’ from ‘int’ makes pointer from integer without a cast [-Wint-conversion]
   37 |     #define __OPEN_WRITE(__FS, __NAME)                  open(__NAME, O_RDWR | O_CREAT, S_IRWXU)
      |                                                         ^~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:437:18: note: in expansion of macro ‘__OPEN_WRITE’
  437 |     void *File = __OPEN_WRITE(fs, ImageName);
      |                  ^~~~~~~~~~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:454:26: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  454 |             ret+=__WRITE(File, img_rgb888, rgb888_size);
      |                          ^~~~
      |                          |
      |                          void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:460:26: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  460 |             ret+=__WRITE(File, img_rgb888, rgb888_size);
      |                          ^~~~
      |                          |
      |                          void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:473:26: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  473 |             ret+=__WRITE(File,OutBuffer +(CHUNK_SIZE*i), CHUNK_SIZE);
      |                          ^~~~
      |                          |
      |                          void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:476:26: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  476 |             ret+=__WRITE(File,OutBuffer+(CHUNK_SIZE*steps) , ((W*H*PixelSize) % CHUNK_SIZE)*sizeof(unsigned char));
      |                          ^~~~
      |                          |
      |                          void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:479:13: warning: passing argument 1 of ‘close’ makes integer from pointer without a cast [-Wint-conversion]
  479 |     __CLOSE(File);
      |             ^~~~
      |             |
      |             void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:38:63: note: in definition of macro ‘__CLOSE’
   38 |     #define __CLOSE(__FD)                               close(__FD)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/usr/include/unistd.h:353:23: note: expected ‘int’ but argument is of type ‘void *’
  353 | extern int close (int __fd);
      |                   ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/ImgIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c: In function ‘WritePPMHeader’:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:57: warning: ignoring return value of ‘write’, declared with attribute warn_unused_result [-Wunused-result]
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                         ^~~~~~~~~~~~~~~~~~~~~~~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c:404:9: note: in expansion of macro ‘__WRITE’
  404 |         __WRITE(FD,&(Buffer[a]), sizeof(unsigned char));
      |         ^~~~~~~
In file included from /home/marco-gwt/GWT/AutotilerV2/Emulation/at_api.h:21,
                 from /home/marco-gwt/GWT/AutotilerV2/Emulation/Gap.h:18,
                 from /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.c:7:
/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.c: In function ‘AT_TensorGetNextPage’:
/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.c:79:63: warning: cast from pointer to integer of different size [-Wpointer-to-int-cast]
   79 |    AT_HYPERFLASH_FS_CL_COPY((AT_HYPERFLASH_FS_T *) L3_Device, (AT_HYPERFLASH_FS_EXT_ADDR_TYPE) (Addr+Offset), (AT_HYPERFLASH_FS_INT_ADDR_TYPE) L2_BufferAddr, Size, 0, L3_Event);
      |                                                               ^
/home/marco-gwt/GWT/AutotilerV2/Emulation/at_api_emul.h:225:36: note: in definition of macro ‘AT_HYPERFLASH_FS_CL_COPY’
  225 |   __at_hyperflash_fs_copy(*(file), ext, loc, size, dir)
      |                                    ^~~
/home/marco-gwt/GWT/AutotilerV2/Emulation/at_api_emul.h: In function ‘__at_hyperflash_fs_copy’:
/home/marco-gwt/GWT/AutotilerV2/Emulation/at_api_emul.h:173:8: warning: ignoring return value of ‘fread’, declared with attribute warn_unused_result [-Wunused-result]
  173 |   else fread(loc, 1, size, file);
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:46:20: warning: useless storage class specifier in empty declaration
   46 |     typedef struct pi_device {};
      |                    ^~~~~~~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c: In function ‘WriteWavToFileNew’:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:37:57: warning: initialization of ‘void *’ from ‘int’ makes pointer from integer without a cast [-Wint-conversion]
   37 |     #define __OPEN_WRITE(__FS, __NAME)                  open(__NAME, O_RDWR | O_CREAT, S_IRWXU)
      |                                                         ^~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:236:18: note: in expansion of macro ‘__OPEN_WRITE’
  236 |     void *File = __OPEN_WRITE(fs, FileName);
      |                  ^~~~~~~~~~~~
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:328:20: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  328 |     ret += __WRITE(File, header_buffer, WAV_HEADER_SIZE);
      |                    ^~~~
      |                    |
      |                    void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:335:21: warning: passing argument 1 of ‘write’ makes integer from pointer without a cast [-Wint-conversion]
  335 |      ret += __WRITE(File, data, Size);
      |                     ^~~~
      |                     |
      |                     void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:41:63: note: in definition of macro ‘__WRITE’
   41 |     #define __WRITE(__FD, __BUF, __LEN)                 write(__FD, __BUF, __LEN)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/usr/include/unistd.h:366:27: note: expected ‘int’ but argument is of type ‘void *’
  366 | extern ssize_t write (int __fd, const void *__buf, size_t __n) __wur;
      |                       ~~~~^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:338:13: warning: passing argument 1 of ‘close’ makes integer from pointer without a cast [-Wint-conversion]
  338 |     __CLOSE(File);
      |             ^~~~
      |             |
      |             void *
/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:38:63: note: in definition of macro ‘__CLOSE’
   38 |     #define __CLOSE(__FD)                               close(__FD)
      |                                                               ^~~~
In file included from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/fs_switch.h:29,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include/gaplib/wavIO.h:13,
                 from /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c:9:
/usr/include/unistd.h:353:23: note: expected ‘int’ but argument is of type ‘void *’
  353 | extern int close (int __fd);
      |                   ~~~~^~~~
make -f emul.mk clean_model clean all DUMP_TENSORS=0 SMALL=0 MEDIUM=1 LARGE=0 WITH_MFCC=1 USE_POWER=1
make[1]: Entering directory '/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting'
script model/nntool_script
GEN ... /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c
rm -f -rf BUILD_MODEL_SQ8_EMUL
rm -f -r BUILD_EMUL
rm -f kws_ds_cnn_emul
mkdir BUILD_MODEL_SQ8_EMUL
cp model/KWS_ds_cnn_m_quant_power.tflite BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite
echo "GENERATING NNTOOL STATE FILE"
GENERATING NNTOOL STATE FILE
nntool -s model/nntool_script BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite -q
settings - set log level to INFO
log_level - was: 'INFO'
now: 'INFO'
open - opening graph file BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite load_quantization = True
tflite - Importing TFLITE model version 3
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
forwards SOFTMAX_0_11 in: -35.73<(i8-0.00)*0.27912489<35.45 out: None stop [] fusion False
handler SoftmaxTanHMult selected for SoftMaxParameters(SOFTMAX_0_11)
forwards handler SOFTMAX_0_11 returned in: -64.00<(i8-0.00)*0.50000000<63.50 forced out: -1.00<(i16-0.00)*0.00003052<1.00 fusion False
forwards in edge 0 does not match was -35.73<(i8-0.00)*0.27912489<35.45 need -64.00<(i8-0.00)*0.50000000<63.50 forced
go backwackwards to F 12x1x1x172 B 1 
backwards FULLY_CONNECTED_0_10 in: -9.24<(i8-0.00)*0.07214916<9.16,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced stop SOFTMAX_0_11 fusion False
handler FilterMult selected for FcParameters(FULLY_CONNECTED_0_10)
filter_mult - selecting SQ8 software kernel filter quantizer
filter_mult - node FULLY_CONNECTED_0_10 output forced to range [-64.]/[63.5] - actual range [-35.72799]/[35.448853] symmetric
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 input from c, out_cin_c, out_c to chw, out_cin_chw, out_c order - rerun adjust command
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 output from c to chw order - rerun adjust command
backwards handler FULLY_CONNECTED_0_10 returned in: -9.24<(i8-0.00)*0.07214916<9.16,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced force_removed False fusion False
backwards finished in_edges FULLY_CONNECTED_0_10
backwards out edge 0 does not match was -35.73<(i8-0.00)*0.27912489<35.45 need -64.00<(i8-0.00)*0.50000000<63.50 forced
---- STOPPED AT SOFTMAX_0_11
backwards finished out_edges FULLY_CONNECTED_0_10
forwards finished in edges SOFTMAX_0_11
forwards at SOFTMAX_0_11 on out edge 0
forwards output_1 in: -1.00<(i16-0.00)*0.00003052<1.00 out: None stop [] fusion False
handler OutputMult selected for OutputParameters(output_1)
forwards handler output_1 returned in: -1.00<(i16-0.00)*0.00003052<1.00 out: -1.00<(i16-0.00)*0.00003052<1.00 fusion False
forwards finished in edges output_1
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
debug - was: False
now: True
adjust_order - adding transposes to correct tensor order for AT kernels
set_aliases - looking for aliased edges
eliminate_transposes - eliminating unnecessary transposes
eliminate_transposes - search for transposes
eliminate_transposes - ++ Starting up from CONV_2D_0_0[1]
eliminate_transposes - looking up at DSCNNconv_1weights_quantFakeQu[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_1weights_quantFakeQu - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_0[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_0[0]
eliminate_transposes - looking down at CONV_2D_0_0_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_1 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_0[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - looking up at DSCNNconv_ds_1dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_2[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_2 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_2[1]
eliminate_transposes - looking up at DSCNNconv_ds_1pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_2[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_2[0]
eliminate_transposes - looking down at CONV_2D_0_2_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_3 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_2[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - looking up at DSCNNconv_ds_2dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_4[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_4 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_4[1]
eliminate_transposes - looking up at DSCNNconv_ds_2pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_4[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_4[0]
eliminate_transposes - looking down at CONV_2D_0_4_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_5 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_4[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - looking up at DSCNNconv_ds_3dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_6[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_6 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_6[1]
eliminate_transposes - looking up at DSCNNconv_ds_3pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_6[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_6[0]
eliminate_transposes - looking down at CONV_2D_0_6_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_7 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_6[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - looking up at DSCNNconv_ds_4dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_8[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_8 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_8[1]
eliminate_transposes - looking up at DSCNNconv_ds_4pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_8[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_8[0]
eliminate_transposes - looking down at CONV_2D_0_8_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at AVERAGE_POOL_2D_0_9[0] transpose [1, 2, 0]
eliminate_transposes - accepted AVERAGE_POOL_2D_0_9 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_8[0]
eliminate_transposes - ++ Starting down from AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - looking down at FULLY_CONNECTED_0_10[0] transpose [1, 2, 0]
eliminate_transposes - accepted FULLY_CONNECTED_0_10 - linear layer reorder input
eliminate_transposes - ++ Found results for AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - eliminate transposes
eliminate_transposes_actions - Start Action (up): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_1weights_quantFakeQu reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_1weights_quantFakeQu
eliminate_transposes_actions - Start Action (down): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_2
eliminate_transposes_actions - Start Action (up): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_4
eliminate_transposes_actions - Start Action (up): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_6
eliminate_transposes_actions - Start Action (up): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_8
eliminate_transposes_actions - Start Action (up): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose in[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - End Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - Start Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - reorder linear layer FULLY_CONNECTED_0_10 in with shape 1x1x172 transposed (2, 0, 1)
eliminate_transposes_actions - End Action (down): FULLY_CONNECTED_0_10
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - search for transposes
eliminate_transposes - no transposes to eliminate found
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - no further transpose sequences found
set_aliases - looking for aliased edges
nngraph - adjusted order
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
duplicate_operations - match_duplicate_operations does not handle quantized graphs
match_gap_conv - fusing nodes CONV_2D_0_0,CONV_2D_0_0_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_1,DEPTHWISE_CONV_2D_0_1_activation
match_gap_conv - fusing nodes CONV_2D_0_2,CONV_2D_0_2_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_3,DEPTHWISE_CONV_2D_0_3_activation
match_gap_conv - fusing nodes CONV_2D_0_4,CONV_2D_0_4_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_5,DEPTHWISE_CONV_2D_0_5_activation
match_gap_conv - fusing nodes CONV_2D_0_6,CONV_2D_0_6_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_7,DEPTHWISE_CONV_2D_0_7_activation
match_gap_conv - fusing nodes CONV_2D_0_8,CONV_2D_0_8_activation
matcher - ++ fusion fuse_gap_convs modified graph
set_aliases - looking for aliased edges
set_aliases - looking for aliased edges
duplicate_operations - match_duplicate_operations does not handle quantized graphs
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
graph_produce_node_names - was: False
now: True
graph_produce_operinfos - was: False
now: True
graph_monitor_cycles - was: False
now: True
graph_const_exec_from_flash - was: False
now: False
save_state - saved state to /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.json
echo "GENERATING AUTOTILER MODEL"
GENERATING AUTOTILER MODEL
nntool -g -M BUILD_MODEL_SQ8_EMUL -m KWS_ds_cnn_m_quantModel.c -T BUILD_MODEL_SQ8_EMUL/tensors -H KWS_ds_cnn_m_quantInfo.h  BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.json
settings - set log level to INFO
log_level - was: 'INFO'
now: 'INFO'
open - opening graph file BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quant.tflite load_quantization = True
tflite - Importing TFLITE model version 3
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
forwards SOFTMAX_0_11 in: -35.73<(i8-0.00)*0.27912489<35.45 out: None stop [] fusion False
handler SoftmaxTanHMult selected for SoftMaxParameters(SOFTMAX_0_11)
forwards handler SOFTMAX_0_11 returned in: -64.00<(i8-0.00)*0.50000000<63.50 forced out: -1.00<(i16-0.00)*0.00003052<1.00 fusion False
forwards in edge 0 does not match was -35.73<(i8-0.00)*0.27912489<35.45 need -64.00<(i8-0.00)*0.50000000<63.50 forced
go backwackwards to F 12x1x1x172 B 1 
backwards FULLY_CONNECTED_0_10 in: -9.24<(i8-0.00)*0.07214916<9.16,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced stop SOFTMAX_0_11 fusion False
handler FilterMult selected for FcParameters(FULLY_CONNECTED_0_10)
filter_mult - selecting SQ8 software kernel filter quantizer
filter_mult - node FULLY_CONNECTED_0_10 output forced to range [-64.]/[63.5] - actual range [-35.72799]/[35.448853] symmetric
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 input from c, out_cin_c, out_c to chw, out_cin_chw, out_c order - rerun adjust command
unified_quantization_handler - indicating change of FULLY_CONNECTED_0_10 output from c to chw order - rerun adjust command
backwards handler FULLY_CONNECTED_0_10 returned in: -9.24<(i8-0.00)*0.07214916<9.16,chan<(i8-0.00)*chan<chan,chan<(i32-0.00)*chan<chan out: -64.00<(i8-0.00)*0.50000000<63.50 forced force_removed False fusion False
backwards finished in_edges FULLY_CONNECTED_0_10
backwards out edge 0 does not match was -35.73<(i8-0.00)*0.27912489<35.45 need -64.00<(i8-0.00)*0.50000000<63.50 forced
---- STOPPED AT SOFTMAX_0_11
backwards finished out_edges FULLY_CONNECTED_0_10
forwards finished in edges SOFTMAX_0_11
forwards at SOFTMAX_0_11 on out edge 0
forwards output_1 in: -1.00<(i16-0.00)*0.00003052<1.00 out: None stop [] fusion False
handler OutputMult selected for OutputParameters(output_1)
forwards handler output_1 returned in: -1.00<(i16-0.00)*0.00003052<1.00 out: -1.00<(i16-0.00)*0.00003052<1.00 fusion False
forwards finished in edges output_1
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
debug - was: False
now: True
adjust_order - adding transposes to correct tensor order for AT kernels
set_aliases - looking for aliased edges
eliminate_transposes - eliminating unnecessary transposes
eliminate_transposes - search for transposes
eliminate_transposes - ++ Starting up from CONV_2D_0_0[1]
eliminate_transposes - looking up at DSCNNconv_1weights_quantFakeQu[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_1weights_quantFakeQu - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_0[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_0[0]
eliminate_transposes - looking down at CONV_2D_0_0_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_1 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_0[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - looking up at DSCNNconv_ds_1dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_1_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_2[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_2 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_1[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_2[1]
eliminate_transposes - looking up at DSCNNconv_ds_1pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_1pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_2[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_2[0]
eliminate_transposes - looking down at CONV_2D_0_2_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_3 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_2[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - looking up at DSCNNconv_ds_2dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_3_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_4[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_4 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_3[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_4[1]
eliminate_transposes - looking up at DSCNNconv_ds_2pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_2pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_4[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_4[0]
eliminate_transposes - looking down at CONV_2D_0_4_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_5 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_4[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - looking up at DSCNNconv_ds_3dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_5_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_6[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_6 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_5[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_6[1]
eliminate_transposes - looking up at DSCNNconv_ds_3pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_3pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_6[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_6[0]
eliminate_transposes - looking down at CONV_2D_0_6_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7[0] transpose [1, 2, 0]
eliminate_transposes - accepted DEPTHWISE_CONV_2D_0_7 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_6[0]
eliminate_transposes - ++ Starting up from DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - looking up at DSCNNconv_ds_4dw_convweights_q[0] transpose [3, 0, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4dw_convweights_q - constant input - transpose constant [3, 0, 1, 2]
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[1]
eliminate_transposes - ++ Starting down from DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - looking down at DEPTHWISE_CONV_2D_0_7_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at CONV_2D_0_8[0] transpose [1, 2, 0]
eliminate_transposes - accepted CONV_2D_0_8 - transpose in (1)
eliminate_transposes - ++ Found results for DEPTHWISE_CONV_2D_0_7[0]
eliminate_transposes - ++ Starting up from CONV_2D_0_8[1]
eliminate_transposes - looking up at DSCNNconv_ds_4pw_convweights_q[0] transpose [0, 3, 1, 2]
eliminate_transposes - accepted DSCNNconv_ds_4pw_convweights_q - constant input - transpose constant [0, 3, 1, 2]
eliminate_transposes - ++ Found results for CONV_2D_0_8[1]
eliminate_transposes - ++ Starting down from CONV_2D_0_8[0]
eliminate_transposes - looking down at CONV_2D_0_8_activation[0] transpose [1, 2, 0]
eliminate_transposes - looking down at AVERAGE_POOL_2D_0_9[0] transpose [1, 2, 0]
eliminate_transposes - accepted AVERAGE_POOL_2D_0_9 - transpose in (1)
eliminate_transposes - ++ Found results for CONV_2D_0_8[0]
eliminate_transposes - ++ Starting down from AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - looking down at FULLY_CONNECTED_0_10[0] transpose [1, 2, 0]
eliminate_transposes - accepted FULLY_CONNECTED_0_10 - linear layer reorder input
eliminate_transposes - ++ Found results for AVERAGE_POOL_2D_0_9[0]
eliminate_transposes - eliminate transposes
eliminate_transposes_actions - Start Action (up): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_1weights_quantFakeQu reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_1weights_quantFakeQu
eliminate_transposes_actions - Start Action (down): CONV_2D_0_0
eliminate_transposes_actions - CONV_2D_0_0 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_0 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_1
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_1 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_2
eliminate_transposes_actions - Start Action (up): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_1pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_1pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_2
eliminate_transposes_actions - CONV_2D_0_2 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_2 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_3
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_3 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_4
eliminate_transposes_actions - Start Action (up): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_2pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_2pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_4
eliminate_transposes_actions - CONV_2D_0_4 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_4 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_5
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_5 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_6
eliminate_transposes_actions - Start Action (up): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_3pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_3pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_6
eliminate_transposes_actions - CONV_2D_0_6 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_6 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [3, 0, 1, 2], None]
eliminate_transposes_actions - End Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - Start Action (up): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4dw_convweights_q reorder constant input to (3, 0, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4dw_convweights_q
eliminate_transposes_actions - Start Action (down): DEPTHWISE_CONV_2D_0_7
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - DEPTHWISE_CONV_2D_0_7 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[0]
eliminate_transposes_actions - transpose is now [None, [0, 3, 1, 2], None]
eliminate_transposes_actions - End Action (down): CONV_2D_0_8
eliminate_transposes_actions - Start Action (up): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose in[1]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint in[1] to ['out_c', 'in_c', 'h', 'w']
eliminate_transposes_actions - DSCNNconv_ds_4pw_convweights_q reorder constant input to (0, 3, 1, 2)
eliminate_transposes_actions - End Action (up): DSCNNconv_ds_4pw_convweights_q
eliminate_transposes_actions - Start Action (down): CONV_2D_0_8
eliminate_transposes_actions - CONV_2D_0_8 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - CONV_2D_0_8 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint in[0] to ['c', 'h', 'w']
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose in[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - End Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - Start Action (down): AVERAGE_POOL_2D_0_9
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 delete transpose out[0]
eliminate_transposes_actions - transpose is now None
eliminate_transposes_actions - AVERAGE_POOL_2D_0_9 set hint out[0] to ['c', 'h', 'w']
eliminate_transposes_actions - reorder linear layer FULLY_CONNECTED_0_10 in with shape 1x1x172 transposed (2, 0, 1)
eliminate_transposes_actions - End Action (down): FULLY_CONNECTED_0_10
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - search for transposes
eliminate_transposes - no transposes to eliminate found
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
eliminate_transposes - no further transpose sequences found
set_aliases - looking for aliased edges
nngraph - adjusted order
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
duplicate_operations - match_duplicate_operations does not handle quantized graphs
match_gap_conv - fusing nodes CONV_2D_0_0,CONV_2D_0_0_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_1,DEPTHWISE_CONV_2D_0_1_activation
match_gap_conv - fusing nodes CONV_2D_0_2,CONV_2D_0_2_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_3,DEPTHWISE_CONV_2D_0_3_activation
match_gap_conv - fusing nodes CONV_2D_0_4,CONV_2D_0_4_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_5,DEPTHWISE_CONV_2D_0_5_activation
match_gap_conv - fusing nodes CONV_2D_0_6,CONV_2D_0_6_activation
match_gap_conv - fusing nodes DEPTHWISE_CONV_2D_0_7,DEPTHWISE_CONV_2D_0_7_activation
match_gap_conv - fusing nodes CONV_2D_0_8,CONV_2D_0_8_activation
matcher - ++ fusion fuse_gap_convs modified graph
set_aliases - looking for aliased edges
set_aliases - looking for aliased edges
duplicate_operations - match_duplicate_operations does not handle quantized graphs
nngraph - update graph dimensions
set_aliases - looking for aliased edges
nngraph - calculate liveness
graph_produce_node_names - was: False
now: True
graph_produce_operinfos - was: False
now: True
graph_monitor_cycles - was: False
now: True
graph_const_exec_from_flash - was: False
now: False
generator - Saving model to BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantModel.c
code_generator - edge from step 1 CONV_2D_0_0_r_hwc_chw is not used and is replaced with edge from step input_1:0 0 cname: Input_1
generator - Writing constants to BUILD_MODEL_SQ8_EMUL
echo "COMPILING AUTOTILER MODEL"
COMPILING AUTOTILER MODEL
gcc -g -o BUILD_MODEL_SQ8_EMUL/GenTile -I. -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/CNN_Generators -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8 -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Generator_Util.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/CNN_Copy_Generators.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators/SSD_Generators.c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeGenerator.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/CNN_Generators_SQ8.c /home/marco-gwt/GWT/AutotilerV2/CNN_Generators_SQ8/RNN_Generators_SQ8.c BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantModel.c /home/marco-gwt/GWT/AutotilerV2/install/lib/libtile.a -lSDL2 -lSDL2_ttf 
echo "RUNNING AUTOTILER MODEL"
RUNNING AUTOTILER MODEL
BUILD_MODEL_SQ8_EMUL/GenTile -o BUILD_MODEL_SQ8_EMUL -c BUILD_MODEL_SQ8_EMUL -f BUILD_MODEL_SQ8_EMUL --L1 48736 --L2 350000 --L3 6388608
InFeat: 1, OutFeat: 172
Conv => W:  10, Pad:[1,2] PadT:[1,2] => Wc: 10, Filter:[4,10]
     => H:  49, Pad:[4,5] PadT:[4,5] => Hc: 25
Pool => Wc: 10, Pad:[0,0] => Wo: 10, Filter:[1,1]
     => Hc: 25, Pad:[0,0] => Ho: 25
OverlapC: 8
OverlapP: 0
TileCons: 2
UsedIn  : [10 x 49]
UsedC   : [10 x 25]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConvNxMStrideSxSy_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1763000

==== Process Tiling For User Kernel:            S4_Conv2d_172x1x10x4_Relu =======================
S4_Conv2d_172x1x10x4_Relu Partition[0] Size = 194929 (Min:    200, Max: 275121), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=25
	                  In Dim:  58, TileOverlap:  8, Ratio: 2.000000
	                 Out Dim:  25, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  25, TileOverlap:  0, Ratio: 1.000000

S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: Bias, was using 704 Bytes will require 688 Bytes buffer
S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: Scale, was using 176 Bytes will require 172 Bytes buffer
S4_Conv2d_172x1x10x4_Relu Full buffering on Arg: ScaleN, was using 176 Bytes will require 172 Bytes buffer
S4_Conv2d_172x1x10x4_Relu, TiledSpace: Tile0 Iteration Count: 4 Parametric Space: [D1, M0=88] Parametric Space: [D0, M1=1]
              In : Ratio: 2.000000, FixDim:     10, VarDim:     22 [    49], Size:    440, Total:     440, Move:       1460 (Decl x 2.979592) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:    1128, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:    1300, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:    1472, Move:        172 (Decl x 1.000000) L2
@         Filter : Ratio: 0.000000,                                          Size:   7040, Total:    8512, Move:       6880 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     10, VarDim:      7 [    25], Size:  12320, Total:   20832, Move:      43000 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:     10, VarDim:      7 [    25], Size:  24640, Total:   45472, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   45484, Move:          9 (Decl x 1.000000) L2
S4_Conv2d_172x1x10x4_Relu - IterSpace: Tile0 - L1 Memory:  45484, L2Move: 52381, L3Move: 0, Tiling Overhead: 1.018868
S4_Conv2d_172x1x10x4_Relu Partial buffering on Arg: Filter, From: D0 To: D1. Current is (Par) 1 x [W:1, H:1] x 40 => Partial buffer size is 7040 Bytes
S4_Conv2d_172x1x10x4_Relu Found Parametric value for space D1 (Initial: 172, Div: 8) = 88 [88*1 + 84] and space D0 (Initial: 1, Div: 4) = 1 [1*1 + 0], Iteration for Tiled Space: 4
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:         In, Size:    220, Base1:      0, Base2:    220
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:       Bias, Size:    688, Base1:    440, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:      Scale, Size:    172, Base1:   1128, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:     ScaleN, Size:    172, Base1:   1300, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:     Filter, Size:   3520, Base1:   1472, Base2:   4992
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:        Out, Size:   6160, Base1:   8512, Base2:  14672
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:    ConvOut, Size:  24640, Base1:  20832, Base2:      0
Ker: S4_Conv2d_172x1x10x4_Relu, Arg:      Infos, Size:     12, Base1:  45472, Base2:      0
S4_Conv2d_172x1x10x4_Relu For Iter Space: 0 Iteration count:   4 (Last one is truncated), Given L1 Memory:  48736, Used L1 Memory:  45484, Reusable Memory: 3252, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  10, Pad:[0,1] PadT:[0,1] => Wc: 5, Filter:[3,3]
     => H:  25, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 1
OverlapP: 0
TileCons: 2
UsedIn  : [10 x 25]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride2B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:             S7_Conv2d_172x1x3x3_Relu =======================
S7_Conv2d_172x1x3x3_Relu Partition[0] Size =  63665 (Min:     60, Max: 165257), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=13
	                  In Dim:  27, TileOverlap:  1, Ratio: 2.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 384 Bytes will require 688 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 96 Bytes will require 172 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 96 Bytes will require 172 Bytes buffer
S7_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 864 Bytes will require 1548 Bytes buffer
S7_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=48]
              In : Ratio: 2.000000, FixDim:     10, VarDim:     25 [    25], Size:  24000, Total:   24000, Move:      43000 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   24688, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   24860, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   25032, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   26580, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:   6240, Total:   32820, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  12480, Total:   45300, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   45312, Move:          9 (Decl x 1.000000) L2
S7_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  45312, L2Move: 56769, L3Move: 0, Tiling Overhead: 1.000000
S7_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 48 [48*3 + 28], Iteration for Tiled Space: 1
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:         In, Size:  12000, Base1:      0, Base2:  12000
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  24000, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  24688, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  24860, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  25032, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   3120, Base1:  26580, Base2:  29700
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  12480, Base1:  32820, Base2:      0
Ker: S7_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  45300, Base2:      0
S7_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  45312, Reusable Memory: 3424, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S10_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S10_Conv2d_172x172x1x1_Relu =======================
S10_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S10_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S10_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S10_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S10_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S10_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S10_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S10_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S10_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S10_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S10_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S13_Conv2d_172x1x3x3_Relu =======================
S13_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S13_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S13_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S13_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S13_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S13_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S13_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S16_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S16_Conv2d_172x172x1x1_Relu =======================
S16_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S16_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S16_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S16_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S16_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S16_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S16_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S16_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S16_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S16_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S16_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S19_Conv2d_172x1x3x3_Relu =======================
S19_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S19_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S19_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S19_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S19_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S19_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S19_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S22_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S22_Conv2d_172x172x1x1_Relu =======================
S22_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S22_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S22_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S22_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S22_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S22_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S22_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S22_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S22_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S22_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S22_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[1,1] PadT:[1,1] => Wc: 5, Filter:[3,3]
     => H:  13, Pad:[1,1] PadT:[1,1] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 2
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
         ConvKerName: KerParConvDW3x3Stride1B32_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 111800

==== Process Tiling For User Kernel:            S25_Conv2d_172x1x3x3_Relu =======================
S25_Conv2d_172x1x3x3_Relu Partition[0] Size =  56785 (Min:     30, Max:  98177), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=13
	                  In Dim:  15, TileOverlap:  2, Ratio: 1.000000
	                 Out Dim:  13, TileOverlap:  0, Ratio: 1.000000
	             ConvOut Dim:  13, TileOverlap:  0, Ratio: 1.000000

S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Bias, was using 640 Bytes will require 688 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Scale, was using 160 Bytes will require 172 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: ScaleN, was using 160 Bytes will require 172 Bytes buffer
S25_Conv2d_172x1x3x3_Relu Full buffering on Arg: Filter, was using 1440 Bytes will require 1548 Bytes buffer
S25_Conv2d_172x1x3x3_Relu, TiledSpace: Tile0 Iteration Count: 1 Parametric Space: [D0, M0=80]
              In : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   10400, Move:      11180 (Decl x 1.000000) L2
*           Bias : Ratio: 0.000000,                                          Size:    688, Total:   11088, Move:        688 (Decl x 1.000000) L2
*          Scale : Ratio: 0.000000,                                          Size:    172, Total:   11260, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 0.000000,                                          Size:    172, Total:   11432, Move:        172 (Decl x 1.000000) L2
*         Filter : Ratio: 0.000000,                                          Size:   1548, Total:   12980, Move:       1548 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  10400, Total:   23380, Move:      11180 (Decl x 1.000000) L2
*        ConvOut : Ratio: 1.000000, FixDim:      5, VarDim:     13 [    13], Size:  20800, Total:   44180, Move:          0 (Decl x 0.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:   44192, Move:          9 (Decl x 1.000000) L2
S25_Conv2d_172x1x3x3_Relu - IterSpace: Tile0 - L1 Memory:  44192, L2Move: 24949, L3Move: 0, Tiling Overhead: 1.000000
S25_Conv2d_172x1x3x3_Relu Found Parametric value for space D0 (Initial: 172, Div: 8) = 80 [80*2 + 12], Iteration for Tiled Space: 1
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:         In, Size:   5200, Base1:      0, Base2:   5200
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:       Bias, Size:    688, Base1:  10400, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:      Scale, Size:    172, Base1:  11088, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:     ScaleN, Size:    172, Base1:  11260, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:     Filter, Size:   1548, Base1:  11432, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:        Out, Size:   5200, Base1:  12980, Base2:  18180
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:    ConvOut, Size:  20800, Base1:  23380, Base2:      0
Ker: S25_Conv2d_172x1x3x3_Relu, Arg:      Infos, Size:     12, Base1:  44180, Base2:      0
S25_Conv2d_172x1x3x3_Relu For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  44192, Reusable Memory: 4544, Used L2 Memory: 0
=================================================================================================

InFeat: 172, OutFeat: 172
Conv => W:  5, Pad:[0,0] PadT:[0,0] => Wc: 5, Filter:[1,1]
     => H:  13, Pad:[0,0] PadT:[0,0] => Hc: 13
Pool => Wc: 5, Pad:[0,0] => Wo: 5, Filter:[1,1]
     => Hc: 13, Pad:[0,0] => Ho: 13
OverlapC: 0
OverlapP: 0
TileCons: 1
UsedIn  : [5 x 13]
UsedC   : [5 x 13]
      SetBiasKerName: KerParSetBiasB32_SQ8
         ConvKerName: KerParConv1x1Stride1_SQ8
  DPReductionKerName: KerParReduct_CC_ReLU_SQ8
Nb Oper : 1934140
Mapping this convolution to matrix multiplication
CNN_MatMul_SQ8: S28_Conv2d_172x172x1x1_Relu
In1  => W:  172, H:  172 
In2  => W:   65, H:  172, w:    5, h:   13, Sx: 1, Sy: 1
Out  => W:   65, H:  172 => Line First
       MatMulKerName: KerParMatMulB32_2x4_ReLU_SQ8

==== Process Tiling For User Kernel:          S28_Conv2d_172x172x1x1_Relu =======================
S28_Conv2d_172x172x1x1_Relu Partition[0] Size =   1401 (Min:   1376, Max:  22401), Fraction:       0.20, Giving:   9854 Bytes out of  48736 Bytes
S28_Conv2d_172x172x1x1_Relu Partition[1] Size =   5528 (Min:   2752, Max:  83344), Fraction:       0.80, Giving:  38881 Bytes out of  48736 Bytes

Reference object:                  In1, Dim=172
	                 In1 Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                Bias Dim: 172, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim: 172, TileOverlap:  0, Ratio: 1.000000
	               Scale Dim: 172, TileOverlap:  0, Ratio: 1.000000
	              ScaleN Dim: 172, TileOverlap:  0, Ratio: 1.000000

S28_Conv2d_172x172x1x1_Relu, TiledSpace: Tile1 Iteration Count: 3
*        KerBuff : Ratio: 0.000000,                                          Size:    688, Total:     688, Move:          0 (Decl x 0.000000) L2
             In1 : Ratio: 1.000000, FixDim:    172, VarDim:     72 [   172], Size:  24768, Total:   25456, Move:      29584 (Decl x 1.000000) L2
*           Bias : Ratio: 1.000000,                                          Size:    688, Total:   26144, Move:        688 (Decl x 1.000000) L2
             Out : Ratio: 1.000000, FixDim:     65, VarDim:     72 [   172], Size:   9360, Total:   35504, Move:      11180 (Decl x 1.000000) L2
*          Scale : Ratio: 1.000000,                                          Size:    172, Total:   35676, Move:        172 (Decl x 1.000000) L2
*         ScaleN : Ratio: 1.000000,                                          Size:    172, Total:   35848, Move:        172 (Decl x 1.000000) L2
S28_Conv2d_172x172x1x1_Relu - IterSpace: Tile1 - L1 Memory:  35848, L2Move: 41796, L3Move: 0, Tiling Overhead: 1.000000
S28_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:    KerBuff, Size:    688, Base1:      0, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        In1, Size:  12384, Base1:    688, Base2:  13072
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:       Bias, Size:    688, Base1:  25456, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        Out, Size:   4680, Base1:  26144, Base2:  30824
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:      Scale, Size:    172, Base1:  35504, Base2:      0
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:     ScaleN, Size:    172, Base1:  35676, Base2:      0
S28_Conv2d_172x172x1x1_Relu For Iter Space: 1 Iteration count:   3 (Last one is truncated), Given L1 Memory:  38881, Used L1 Memory:  35848, Reusable Memory: 3032, Used L2 Memory: 0

Reference object:                  In2, Dim=65
	                 In2 Dim:  65, TileOverlap:  0, Ratio: 1.000000

S28_Conv2d_172x172x1x1_Relu, TiledSpace: Tile0 Iteration Count: 3
             In2 : Ratio: 1.000000, FixDim:    172, VarDim:     28 [    65], Size:   9632, Total:    9632, Move:      33540 (Decl x 3.000000) L2
*          Infos : Ratio: 0.000000,                                          Size:     12, Total:    9644, Move:          9 (Decl x 1.000000) L2
S28_Conv2d_172x172x1x1_Relu - IterSpace: Tile0 - L1 Memory:   9644, L2Move: 33549, L3Move: 0, Tiling Overhead: 2.998391
S28_Conv2d_172x172x1x1_Relu Iteration for Tiled Space: 3
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:        In2, Size:   4816, Base1:  35848, Base2:  40664
Ker: S28_Conv2d_172x172x1x1_Relu, Arg:      Infos, Size:     12, Base1:  45480, Base2:      0
S28_Conv2d_172x172x1x1_Relu For Iter Space: 0 Iteration count:   3 (Last one is truncated), Given L1 Memory:   9854, Used L1 Memory:   9644, Reusable Memory: 208, Used L2 Memory: 0
=================================================================================================

Pool => W: 5, Pad:[0,0] => Wo: 1
     => H: 13, Pad:[0,0] => Ho: 1
OverlapP: 11
TileCons: 2
UsedIn  : [5 x 13]
         PoolKerName: KerParPoolNxMStrideSxSy_SQ8
Nb Oper : 11180

==== Process Tiling For User Kernel:                 S29_AveragePool_13x5 =======================
S29_AveragePool_13x5 Partition[0] Size =  23063 (Min:    130, Max:  22731), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                  Out, Dim=1
	                  In Dim:  13, TileOverlap: 11, Ratio: 2.000000
	                 Out Dim:   1, TileOverlap:  0, Ratio: 1.000000

Kernel: S29_AveragePool_13x5, Total Raw Memory: 11364 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S29_AveragePool_13x5, Arg:         In, Size:  11180, Base1:      0, Base2:      0
Ker: S29_AveragePool_13x5, Arg:        Out, Size:    172, Base1:  11180, Base2:      0
Ker: S29_AveragePool_13x5, Arg:      Infos, Size:     12, Base1:  11352, Base2:      0
S29_AveragePool_13x5 For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:  11364, Reusable Memory: 37372, Used L2 Memory: 0
=================================================================================================

Linear Layer S32_Linear_12x172x1x1, Linear: InDim: 172, OutDim: 12, Activation: None
Linear Kernel: KerParLinearLayerFullFeatB32_SQ8

==== Process Tiling For User Kernel:                S32_Linear_12x172x1x1 =======================
S32_Linear_12x172x1x1 Partition[0] Size =   4491 (Min:      0, Max:   4575), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=1

Kernel: S32_Linear_12x172x1x1, Total Raw Memory: 2332 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S32_Linear_12x172x1x1, Arg:         In, Size:    172, Base1:      0, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:     Filter, Size:   2064, Base1:    172, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:       Bias, Size:     48, Base1:   2236, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:        Out, Size:     12, Base1:   2284, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:      Scale, Size:     12, Base1:   2296, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:     ScaleN, Size:     12, Base1:   2308, Base2:      0
Ker: S32_Linear_12x172x1x1, Arg:      Infos, Size:     12, Base1:   2320, Base2:      0
S32_Linear_12x172x1x1 For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:   2332, Reusable Memory: 46404, Used L2 Memory: 0
=================================================================================================


==== Process Tiling For User Kernel:                          S33_SoftMax =======================
         S33_SoftMax Partition[0] Size =     51 (Min:      8, Max:     63), Fraction:       1.00, Giving:  48736 Bytes out of  48736 Bytes

Reference object:                   In, Dim=12
	                  In Dim:  12, TileOverlap:  0, Ratio: 1.000000
	                 Out Dim:  12, TileOverlap:  0, Ratio: 1.000000

Kernel:          S33_SoftMax, Total Raw Memory: 48 fits into L1 memory 48736. Promoting all kernel arguments to initialized buffers.
Ker: S33_SoftMax, Arg:         In, Size:     12, Base1:      0, Base2:      0
Ker: S33_SoftMax, Arg:        Out, Size:     24, Base1:     12, Base2:      0
Ker: S33_SoftMax, Arg:      Infos, Size:     12, Base1:     36, Base2:      0
         S33_SoftMax For Iter Space: 0 Iteration count:   1, Given L1 Memory:  48736, Used L1 Memory:     48, Reusable Memory: 48688, Used L2 Memory: 0
=================================================================================================

   Symbol:           S32_Output[   In] Adding   Edge From               S32_Linear_12x172x1x1 To                         S33_SoftMax New
   Symbol:           S29_Output[   In] Adding   Edge From                S29_AveragePool_13x5 To               S32_Linear_12x172x1x1 New
   Symbol:           S28_Output[   In] Adding   Edge From         S28_Conv2d_172x172x1x1_Relu To                S29_AveragePool_13x5 New
   Symbol:           S25_Output[   In] Adding   Edge From           S25_Conv2d_172x1x3x3_Relu To         S28_Conv2d_172x172x1x1_Relu New
   Symbol:           S22_Output[   In] Adding   Edge From         S22_Conv2d_172x172x1x1_Relu To           S25_Conv2d_172x1x3x3_Relu New
   Symbol:           S19_Output[   In] Adding   Edge From           S19_Conv2d_172x1x3x3_Relu To         S22_Conv2d_172x172x1x1_Relu New
   Symbol:           S16_Output[   In] Adding   Edge From         S16_Conv2d_172x172x1x1_Relu To           S19_Conv2d_172x1x3x3_Relu New
   Symbol:           S13_Output[   In] Adding   Edge From           S13_Conv2d_172x1x3x3_Relu To         S16_Conv2d_172x172x1x1_Relu New
   Symbol:           S10_Output[   In] Adding   Edge From         S10_Conv2d_172x172x1x1_Relu To           S13_Conv2d_172x1x3x3_Relu New
   Symbol:            S7_Output[   In] Adding   Edge From            S7_Conv2d_172x1x3x3_Relu To         S10_Conv2d_172x172x1x1_Relu New
   Symbol:            S4_Output[   In] Adding   Edge From           S4_Conv2d_172x1x10x4_Relu To            S7_Conv2d_172x1x3x3_Relu New
   Symbol:             Output_1[  Out] Adding   Edge From                         S33_SoftMax To                       __GraphExit__ New
   Symbol:            S33_Infos[   In] Adding   Edge From                      __GraphEntry__ To                         S33_SoftMax New
   Symbol:            S32_Infos[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 New
   Symbol:        S32_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:        S32_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:  Dscnnfc1matmul_bias[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol: Dscnnfc1weights_quantfakequant[   In] Adding   Edge From                      __GraphEntry__ To               S32_Linear_12x172x1x1 Exists
   Symbol:            S29_Infos[   In] Adding   Edge From                      __GraphEntry__ To                S29_AveragePool_13x5 New
   Symbol:            S28_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu New
   Symbol:        S28_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S28_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_4pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_4pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S28_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S25_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu New
   Symbol:        S25_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S25_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_4dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_4dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S25_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S22_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu New
   Symbol:        S22_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S22_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_3pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_3pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S22_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S19_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu New
   Symbol:        S19_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S19_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_3dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_3dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S19_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S16_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu New
   Symbol:        S16_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S16_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_2pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_2pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S16_Conv2d_172x172x1x1_Relu Exists
   Symbol:            S13_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu New
   Symbol:        S13_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol:        S13_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_2dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_2dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To           S13_Conv2d_172x1x3x3_Relu Exists
   Symbol:            S10_Infos[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu New
   Symbol:        S10_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol:        S10_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_1pw_convconv2d_fo[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol: Dscnnconv_ds_1pw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To         S10_Conv2d_172x172x1x1_Relu Exists
   Symbol:             S7_Infos[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu New
   Symbol:         S7_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol:         S7_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_1dw_convdepthwise[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol: Dscnnconv_ds_1dw_convweights_q[   In] Adding   Edge From                      __GraphEntry__ To            S7_Conv2d_172x1x3x3_Relu Exists
   Symbol:             S4_Infos[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu New
   Symbol:         S4_Mul_shift[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol:         S4_Mul_scale[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol: Dscnnconv_1conv2d_fold_bias[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol: Dscnnconv_1weights_quantfakequ[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
   Symbol:              Input_1[   In] Adding   Edge From                      __GraphEntry__ To           S4_Conv2d_172x1x10x4_Relu Exists
After Dynamic Allocation, TopL3: 0, TopL2: 54180 => Alloc: OK

After Const Allocation, TopL3: 0, TopL2: 197153 => Alloc: OK

[FULL] Remapping [54180 .. 197152] to [0 .. 142972] Align compensation: 3
[PART] Remapping [0 .. 54179] to [142976 .. 197155] Align compensation: 0
[PART] Remapping [197153 .. 349999] to [197156 .. 350002] Align compensation: 1
Symbol allocation for graph KWS_ds_cnn_m_quantCNN is sucessfull, L2: 197153 out of 350000, L3: 0 out of 6388608
------------------------------------------------------------------------------------------------------------------------------------------------
Graph structure:

Node   0, Channel   0  0: GraphEntry __GraphEntry__, Operations: 0
                                   (null) =>                        Input_1
                                   (null) => Dscnnconv_1weights_quantfakequ
                                   (null) =>    Dscnnconv_1conv2d_fold_bias
                                   (null) =>                   S4_Mul_scale
                                   (null) =>                   S4_Mul_shift
                                   (null) =>                       S4_Infos
                                   (null) => Dscnnconv_ds_1dw_convweights_q
                                   (null) => Dscnnconv_ds_1dw_convdepthwise
                                   (null) =>                   S7_Mul_scale
                                   (null) =>                   S7_Mul_shift
                                   (null) =>                       S7_Infos
                                   (null) => Dscnnconv_ds_1pw_convweights_q
                                   (null) => Dscnnconv_ds_1pw_convconv2d_fo
                                   (null) =>                  S10_Mul_scale
                                   (null) =>                  S10_Mul_shift
                                   (null) =>                      S10_Infos
                                   (null) => Dscnnconv_ds_2dw_convweights_q
                                   (null) => Dscnnconv_ds_2dw_convdepthwise
                                   (null) =>                  S13_Mul_scale
                                   (null) =>                  S13_Mul_shift
                                   (null) =>                      S13_Infos
                                   (null) => Dscnnconv_ds_2pw_convweights_q
                                   (null) => Dscnnconv_ds_2pw_convconv2d_fo
                                   (null) =>                  S16_Mul_scale
                                   (null) =>                  S16_Mul_shift
                                   (null) =>                      S16_Infos
                                   (null) => Dscnnconv_ds_3dw_convweights_q
                                   (null) => Dscnnconv_ds_3dw_convdepthwise
                                   (null) =>                  S19_Mul_scale
                                   (null) =>                  S19_Mul_shift
                                   (null) =>                      S19_Infos
                                   (null) => Dscnnconv_ds_3pw_convweights_q
                                   (null) => Dscnnconv_ds_3pw_convconv2d_fo
                                   (null) =>                  S22_Mul_scale
                                   (null) =>                  S22_Mul_shift
                                   (null) =>                      S22_Infos
                                   (null) => Dscnnconv_ds_4dw_convweights_q
                                   (null) => Dscnnconv_ds_4dw_convdepthwise
                                   (null) =>                  S25_Mul_scale
                                   (null) =>                  S25_Mul_shift
                                   (null) =>                      S25_Infos
                                   (null) => Dscnnconv_ds_4pw_convweights_q
                                   (null) => Dscnnconv_ds_4pw_convconv2d_fo
                                   (null) =>                  S28_Mul_scale
                                   (null) =>                  S28_Mul_shift
                                   (null) =>                      S28_Infos
                                   (null) =>                      S29_Infos
                                   (null) => Dscnnfc1weights_quantfakequant
                                   (null) =>            Dscnnfc1matmul_bias
                                   (null) =>                  S32_Mul_scale
                                   (null) =>                  S32_Mul_shift
                                   (null) =>                      S32_Infos
                                   (null) =>                      S33_Infos
	Kernel Memory      : L3:       0, L2:       0
	Kernel Total Memory:       0, L3 moves:       0, L2 moves:       0, Move overhead: 1.000000
	Kernel Operations  :       0 [KernelOper/GraphOper: 0.000000%], Move/Operation ratio: [L3: 0.000000, L2: 0.000000]
	Successors:  2 1 3 4 5 6 7 8 9 10 11 12

    Living Dynamic Symbols: [Input_1] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   1, Channel   1  1:       UKer S4_Conv2d_172x1x10x4_Relu, Operations: 1763000
 I                                     In =>                        Input_1    --L2--    Size:     490, L3_Move:         0, L2_Move:      1460, TileOverhead: 2.979592, L2Buff:     0, Addr: 0
CI PartBuff                        Filter => Dscnnconv_1weights_quantfakequ    --L2--    Size:    6880, L3_Move:         0, L2_Move:      6880, TileOverhead: 1.000000, L2Buff:     0, Addr: 1472
CI Buff                              Bias =>    Dscnnconv_1conv2d_fold_bias    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 440
 O                                    Out =>                      S4_Output    --L2--    Size:   43000, L3_Move:         0, L2_Move:     43000, TileOverhead: 1.000000, L2Buff:     0, Addr: 8512
CI Buff                             Scale =>                   S4_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 1128
CI Buff                            ScaleN =>                   S4_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 1300
CI Buff                             Infos =>                       S4_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45472
	Kernel Memory      : L3:       0, L2:   51411
	Kernel Total Memory:   51411, L3 moves:       0, L2 moves:   52381, Move overhead: 1.018868
	Kernel Operations  : 1763000 [KernelOper/GraphOper: 17.780609%], Move/Operation ratio: [L3: 0.000000, L2: 0.029711]
	Successors:  2

    Living Dynamic Symbols: [Input_1] [S4_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   2, Channel   0  0:       UKer S7_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                      S4_Output    --L2--    Size:   43000, L3_Move:         0, L2_Move:     43000, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_1dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 25032
CI Buff                              Bias => Dscnnconv_ds_1dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 24000
 O                                    Out =>                      S7_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26580
CI Buff                             Scale =>                   S7_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 24688
CI Buff                            ScaleN =>                   S7_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 24860
CI Buff                             Infos =>                       S7_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45300
	Kernel Memory      : L3:       0, L2:   56769
	Kernel Total Memory:   56769, L3 moves:       0, L2 moves:   56769, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.507773]
	Successors:  3

    Living Dynamic Symbols: [S4_Output] [S7_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   3, Channel   0  0:       UKer S10_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                      S7_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_1pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_1pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S10_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S10_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S10_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S10_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  4

    Living Dynamic Symbols: [S7_Output] [S10_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   4, Channel   0  0:       UKer S13_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S10_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_2dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_2dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S13_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S13_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S13_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S13_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  5

    Living Dynamic Symbols: [S10_Output] [S13_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   5, Channel   0  0:       UKer S16_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S13_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_2pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_2pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S16_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S16_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S16_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S16_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  6

    Living Dynamic Symbols: [S13_Output] [S16_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   6, Channel   0  0:       UKer S19_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S16_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_3dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_3dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S19_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S19_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S19_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S19_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  7

    Living Dynamic Symbols: [S16_Output] [S19_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   7, Channel   0  0:       UKer S22_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S19_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_3pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_3pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S22_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S22_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S22_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S22_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  8

    Living Dynamic Symbols: [S19_Output] [S22_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   8, Channel   0  0:       UKer S25_Conv2d_172x1x3x3_Relu, Operations: 111800
 I                                     In =>                     S22_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnconv_ds_4dw_convweights_q    --L2--    Size:    1548, L3_Move:         0, L2_Move:      1548, TileOverhead: 1.000000, L2Buff:     0, Addr: 11432
CI Buff                              Bias => Dscnnconv_ds_4dw_convdepthwise    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 10400
 O                                    Out =>                     S25_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 12980
CI Buff                             Scale =>                  S25_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11088
CI Buff                            ScaleN =>                  S25_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11260
CI Buff                             Infos =>                      S25_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 44180
	Kernel Memory      : L3:       0, L2:   24949
	Kernel Total Memory:   24949, L3 moves:       0, L2 moves:   24949, Move overhead: 1.000000
	Kernel Operations  :  111800 [KernelOper/GraphOper: 1.127551%], Move/Operation ratio: [L3: 0.000000, L2: 0.223157]
	Successors:  9

    Living Dynamic Symbols: [S22_Output] [S25_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node   9, Channel   0  0:       UKer S28_Conv2d_172x172x1x1_Relu, Operations: 1922960
 I                                    In2 =>                     S25_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     33540, TileOverhead: 3.000000, L2Buff:     0, Addr: 35848
CI                                    In1 => Dscnnconv_ds_4pw_convweights_q    --L2--    Size:   29584, L3_Move:         0, L2_Move:     29584, TileOverhead: 1.000000, L2Buff:     0, Addr: 688
CI Buff                              Bias => Dscnnconv_ds_4pw_convconv2d_fo    --L2--    Size:     688, L3_Move:         0, L2_Move:       688, TileOverhead: 1.000000, L2Buff:     0, Addr: 25456
 O                                    Out =>                     S28_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 26144
CI Buff                             Scale =>                  S28_Mul_scale    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35504
CI Buff                            ScaleN =>                  S28_Mul_shift    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 35676
CI Buff                             Infos =>                      S28_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 45480
	Kernel Memory      : L3:       0, L2:   52985
	Kernel Total Memory:   52985, L3 moves:       0, L2 moves:   75345, Move overhead: 1.422006
	Kernel Operations  : 1922960 [KernelOper/GraphOper: 19.393873%], Move/Operation ratio: [L3: 0.000000, L2: 0.039182]
	Successors:  10

    Living Dynamic Symbols: [S25_Output] [S28_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  10, Channel   0  0:       UKer S29_AveragePool_13x5, Operations: 11180
 I Buff                                In =>                     S28_Output    --L2--    Size:   11180, L3_Move:         0, L2_Move:     11180, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
 O Buff                               Out =>                     S29_Output    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 11180
CI Buff                             Infos =>                      S29_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 11352
	Kernel Memory      : L3:       0, L2:   11361
	Kernel Total Memory:   11361, L3 moves:       0, L2 moves:   11361, Move overhead: 1.000000
	Kernel Operations  :   11180 [KernelOper/GraphOper: 0.112755%], Move/Operation ratio: [L3: 0.000000, L2: 1.016190]
	Successors:  11

    Living Dynamic Symbols: [S28_Output] [S29_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  11, Channel   0  0:       UKer S32_Linear_12x172x1x1, Operations: 2064
 I Buff                                In =>                     S29_Output    --L2--    Size:     172, L3_Move:         0, L2_Move:       172, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
CI Buff                            Filter => Dscnnfc1weights_quantfakequant    --L2--    Size:    2064, L3_Move:         0, L2_Move:      2064, TileOverhead: 1.000000, L2Buff:     0, Addr: 172
CI Buff                              Bias =>            Dscnnfc1matmul_bias    --L2--    Size:      48, L3_Move:         0, L2_Move:        48, TileOverhead: 1.000000, L2Buff:     0, Addr: 2236
 O Buff                               Out =>                     S32_Output    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2284
CI Buff                             Scale =>                  S32_Mul_scale    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2296
CI Buff                            ScaleN =>                  S32_Mul_shift    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 2308
CI Buff                             Infos =>                      S32_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 2320
	Kernel Memory      : L3:       0, L2:    2329
	Kernel Total Memory:    2329, L3 moves:       0, L2 moves:    2329, Move overhead: 1.000000
	Kernel Operations  :    2064 [KernelOper/GraphOper: 0.020816%], Move/Operation ratio: [L3: 0.000000, L2: 1.128392]
	Successors:  12

    Living Dynamic Symbols: [S29_Output] [S32_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  12, Channel   0  0:       UKer S33_SoftMax, Operations: 12
 I Buff                                In =>                     S32_Output    --L2--    Size:      12, L3_Move:         0, L2_Move:        12, TileOverhead: 1.000000, L2Buff:     0, Addr: 0
 O Buff                               Out =>                       Output_1    --L2--    Size:      24, L3_Move:         0, L2_Move:        24, TileOverhead: 1.000000, L2Buff:     0, Addr: 12
CI Buff                             Infos =>                      S33_Infos    --L2--    Size:       9, L3_Move:         0, L2_Move:         9, TileOverhead: 1.000000, L2Buff:     0, Addr: 36
	Kernel Memory      : L3:       0, L2:      45
	Kernel Total Memory:      45, L3 moves:       0, L2 moves:      45, Move overhead: 1.000000
	Kernel Operations  :      12 [KernelOper/GraphOper: 0.000121%], Move/Operation ratio: [L3: 0.000000, L2: 3.750000]
	Successors:  13

    Living Dynamic Symbols: [Output_1] [S32_Output] 

------------------------------------------------------------------------------------------------------------------------------------------------
Node  13, Channel   0  0:  GraphExit __GraphExit__, Operations: 0
                                   (null) =>                       Output_1
	Kernel Memory      : L3:       0, L2:       0
	Kernel Total Memory:       0, L3 moves:       0, L2 moves:       0, Move overhead: 1.000000
	Kernel Operations  :       0 [KernelOper/GraphOper: 0.000000%], Move/Operation ratio: [L3: 0.000000, L2: 0.000000]
	Successors: 

    Living Dynamic Symbols: [Output_1] 

------------------------------------------------------------------------------------------------------------------------------------------------
	Graph nodes max local memory : L3:       0, L2:   56769
	Graph nodes min global memory: L3:       0, L2:   56772
	Graph sum of kernel arguments size:  408702, L3 moves:       0, L2 moves:  499112, Move overhead: 1.221213
	Graph total operations: 9915296


------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Memory bandwidth report:

    Sum of All Kernel's arguments size:  408702, Total L3_Move:         0, Total L2_Move:    499112, Tiling Overhead Average: 1.221213

------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Total minimum memory requirement report:

                     L3 Memory       L2 Memory
       Dynamic               0           54180
         Const               0           30628
         Total               0           56772
------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Graph symbols allocation:

              Input_1  Externally allocated
 Dscnnconv_1weights_quantfakequ  INSTALL: HyperFlash[  0: 13]@ 118336    LOAD:         L2[  0: 13]@ 118336    EXEC:         L2[  0: 13]@ 118336 , Size:    6880
 Dscnnconv_1conv2d_fold_bias  INSTALL: HyperFlash[  0: 13]@ 133472    LOAD:         L2[  0: 13]@ 133472    EXEC:         L2[  0: 13]@ 133472 , Size:     688
         S4_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 139664    LOAD:         L2[  0: 13]@ 139664    EXEC:         L2[  0: 13]@ 139664 , Size:     172
         S4_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 139836    LOAD:         L2[  0: 13]@ 139836    EXEC:         L2[  0: 13]@ 139836 , Size:     172
             S4_Infos  INSTALL: HyperFlash[  0: 13]@ 142808    LOAD:         L2[  0: 13]@ 142808    EXEC:         L2[  0: 13]@ 142808 , Size:       9
 Dscnnconv_ds_1dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 127280    LOAD:         L2[  0: 13]@ 127280    EXEC:         L2[  0: 13]@ 127280 , Size:    1548
 Dscnnconv_ds_1dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 134160    LOAD:         L2[  0: 13]@ 134160    EXEC:         L2[  0: 13]@ 134160 , Size:     688
         S7_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140008    LOAD:         L2[  0: 13]@ 140008    EXEC:         L2[  0: 13]@ 140008 , Size:     172
         S7_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140180    LOAD:         L2[  0: 13]@ 140180    EXEC:         L2[  0: 13]@ 140180 , Size:     172
             S7_Infos  INSTALL: HyperFlash[  0: 13]@ 142820    LOAD:         L2[  0: 13]@ 142820    EXEC:         L2[  0: 13]@ 142820 , Size:       9
 Dscnnconv_ds_1pw_convweights_q  INSTALL: HyperFlash[  0: 13]@      0    LOAD:         L2[  0: 13]@      0    EXEC:         L2[  0: 13]@      0 , Size:   29584
 Dscnnconv_ds_1pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 134848    LOAD:         L2[  0: 13]@ 134848    EXEC:         L2[  0: 13]@ 134848 , Size:     688
        S10_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140352    LOAD:         L2[  0: 13]@ 140352    EXEC:         L2[  0: 13]@ 140352 , Size:     172
        S10_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140524    LOAD:         L2[  0: 13]@ 140524    EXEC:         L2[  0: 13]@ 140524 , Size:     172
            S10_Infos  INSTALL: HyperFlash[  0: 13]@ 142832    LOAD:         L2[  0: 13]@ 142832    EXEC:         L2[  0: 13]@ 142832 , Size:       9
 Dscnnconv_ds_2dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 128828    LOAD:         L2[  0: 13]@ 128828    EXEC:         L2[  0: 13]@ 128828 , Size:    1548
 Dscnnconv_ds_2dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 135536    LOAD:         L2[  0: 13]@ 135536    EXEC:         L2[  0: 13]@ 135536 , Size:     688
        S13_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 140696    LOAD:         L2[  0: 13]@ 140696    EXEC:         L2[  0: 13]@ 140696 , Size:     172
        S13_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 140868    LOAD:         L2[  0: 13]@ 140868    EXEC:         L2[  0: 13]@ 140868 , Size:     172
            S13_Infos  INSTALL: HyperFlash[  0: 13]@ 142844    LOAD:         L2[  0: 13]@ 142844    EXEC:         L2[  0: 13]@ 142844 , Size:       9
 Dscnnconv_ds_2pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  29584    LOAD:         L2[  0: 13]@  29584    EXEC:         L2[  0: 13]@  29584 , Size:   29584
 Dscnnconv_ds_2pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 136224    LOAD:         L2[  0: 13]@ 136224    EXEC:         L2[  0: 13]@ 136224 , Size:     688
        S16_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141040    LOAD:         L2[  0: 13]@ 141040    EXEC:         L2[  0: 13]@ 141040 , Size:     172
        S16_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141212    LOAD:         L2[  0: 13]@ 141212    EXEC:         L2[  0: 13]@ 141212 , Size:     172
            S16_Infos  INSTALL: HyperFlash[  0: 13]@ 142856    LOAD:         L2[  0: 13]@ 142856    EXEC:         L2[  0: 13]@ 142856 , Size:       9
 Dscnnconv_ds_3dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 130376    LOAD:         L2[  0: 13]@ 130376    EXEC:         L2[  0: 13]@ 130376 , Size:    1548
 Dscnnconv_ds_3dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 136912    LOAD:         L2[  0: 13]@ 136912    EXEC:         L2[  0: 13]@ 136912 , Size:     688
        S19_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141384    LOAD:         L2[  0: 13]@ 141384    EXEC:         L2[  0: 13]@ 141384 , Size:     172
        S19_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141556    LOAD:         L2[  0: 13]@ 141556    EXEC:         L2[  0: 13]@ 141556 , Size:     172
            S19_Infos  INSTALL: HyperFlash[  0: 13]@ 142868    LOAD:         L2[  0: 13]@ 142868    EXEC:         L2[  0: 13]@ 142868 , Size:       9
 Dscnnconv_ds_3pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  59168    LOAD:         L2[  0: 13]@  59168    EXEC:         L2[  0: 13]@  59168 , Size:   29584
 Dscnnconv_ds_3pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 137600    LOAD:         L2[  0: 13]@ 137600    EXEC:         L2[  0: 13]@ 137600 , Size:     688
        S22_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 141728    LOAD:         L2[  0: 13]@ 141728    EXEC:         L2[  0: 13]@ 141728 , Size:     172
        S22_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 141900    LOAD:         L2[  0: 13]@ 141900    EXEC:         L2[  0: 13]@ 141900 , Size:     172
            S22_Infos  INSTALL: HyperFlash[  0: 13]@ 142880    LOAD:         L2[  0: 13]@ 142880    EXEC:         L2[  0: 13]@ 142880 , Size:       9
 Dscnnconv_ds_4dw_convweights_q  INSTALL: HyperFlash[  0: 13]@ 131924    LOAD:         L2[  0: 13]@ 131924    EXEC:         L2[  0: 13]@ 131924 , Size:    1548
 Dscnnconv_ds_4dw_convdepthwise  INSTALL: HyperFlash[  0: 13]@ 138288    LOAD:         L2[  0: 13]@ 138288    EXEC:         L2[  0: 13]@ 138288 , Size:     688
        S25_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142072    LOAD:         L2[  0: 13]@ 142072    EXEC:         L2[  0: 13]@ 142072 , Size:     172
        S25_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142244    LOAD:         L2[  0: 13]@ 142244    EXEC:         L2[  0: 13]@ 142244 , Size:     172
            S25_Infos  INSTALL: HyperFlash[  0: 13]@ 142892    LOAD:         L2[  0: 13]@ 142892    EXEC:         L2[  0: 13]@ 142892 , Size:       9
 Dscnnconv_ds_4pw_convweights_q  INSTALL: HyperFlash[  0: 13]@  88752    LOAD:         L2[  0: 13]@  88752    EXEC:         L2[  0: 13]@  88752 , Size:   29584
 Dscnnconv_ds_4pw_convconv2d_fo  INSTALL: HyperFlash[  0: 13]@ 138976    LOAD:         L2[  0: 13]@ 138976    EXEC:         L2[  0: 13]@ 138976 , Size:     688
        S28_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142416    LOAD:         L2[  0: 13]@ 142416    EXEC:         L2[  0: 13]@ 142416 , Size:     172
        S28_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142588    LOAD:         L2[  0: 13]@ 142588    EXEC:         L2[  0: 13]@ 142588 , Size:     172
            S28_Infos  INSTALL: HyperFlash[  0: 13]@ 142904    LOAD:         L2[  0: 13]@ 142904    EXEC:         L2[  0: 13]@ 142904 , Size:       9
            S29_Infos  INSTALL: HyperFlash[  0: 13]@ 142916    LOAD:         L2[  0: 13]@ 142916    EXEC:         L2[  0: 13]@ 142916 , Size:       9
 Dscnnfc1weights_quantfakequant  INSTALL: HyperFlash[  0: 13]@ 125216    LOAD:         L2[  0: 13]@ 125216    EXEC:         L2[  0: 13]@ 125216 , Size:    2064
  Dscnnfc1matmul_bias  INSTALL: HyperFlash[  0: 13]@ 142760    LOAD:         L2[  0: 13]@ 142760    EXEC:         L2[  0: 13]@ 142760 , Size:      48
        S32_Mul_scale  INSTALL: HyperFlash[  0: 13]@ 142928    LOAD:         L2[  0: 13]@ 142928    EXEC:         L2[  0: 13]@ 142928 , Size:      12
        S32_Mul_shift  INSTALL: HyperFlash[  0: 13]@ 142940    LOAD:         L2[  0: 13]@ 142940    EXEC:         L2[  0: 13]@ 142940 , Size:      12
            S32_Infos  INSTALL: HyperFlash[  0: 13]@ 142952    LOAD:         L2[  0: 13]@ 142952    EXEC:         L2[  0: 13]@ 142952 , Size:       9
            S33_Infos  INSTALL: HyperFlash[  0: 13]@ 142964    LOAD:         L2[  0: 13]@ 142964    EXEC:         L2[  0: 13]@ 142964 , Size:       9
             Output_1  Externally allocated
            S4_Output     EXEC:         L2[  1:  2]@ 154156 , Size:   43000
            S7_Output     EXEC:         L2[  2:  3]@ 142976 , Size:   11180
           S10_Output     EXEC:         L2[  3:  4]@ 154156 , Size:   11180
           S13_Output     EXEC:         L2[  4:  5]@ 142976 , Size:   11180
           S16_Output     EXEC:         L2[  5:  6]@ 154156 , Size:   11180
           S19_Output     EXEC:         L2[  6:  7]@ 142976 , Size:   11180
           S22_Output     EXEC:         L2[  7:  8]@ 154156 , Size:   11180
           S25_Output     EXEC:         L2[  8:  9]@ 165336 , Size:   11180
           S28_Output     EXEC:         L2[  9: 10]@ 142976 , Size:   11180
           S29_Output     EXEC:         L2[ 10: 11]@ 154156 , Size:     172
           S32_Output     EXEC:         L2[ 11: 12]@ 142976 , Size:      12
------------------------------------------------------------------------------------------------------------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------
Graph stacked tensors
------------------------------------------------------------------------------------------------------------------------------------------------

Generating Code For User Kernel:           S4_Conv2d_172x1x10x4_Relu
Generating Code For User Kernel:            S7_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S10_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S13_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S16_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S19_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S22_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:           S25_Conv2d_172x1x3x3_Relu
Generating Code For User Kernel:         S28_Conv2d_172x172x1x1_Relu
Generating Code For User Kernel:                S29_AveragePool_13x5
Generating Code For User Kernel:               S32_Linear_12x172x1x1
Generating Code For User Kernel:                         S33_SoftMax
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_1weights_quantfakequ.tensor: 6880 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_1conv2d_fold_bias.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S4_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S7_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_1pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S10_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S13_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_2pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S16_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S19_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_3pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S22_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4dw_convweights_q.tensor: 1548 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4dw_convdepthwise.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S25_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4pw_convweights_q.tensor: 29584 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnconv_ds_4pw_convconv2d_fo.tensor: 172 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Mul_scale.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Mul_shift.tensor: 172 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S28_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S29_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnfc1weights_quantfakequant.tensor: 2064 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/Dscnnfc1matmul_bias.tensor: 12 Word items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Mul_scale.tensor: 12 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Mul_shift.tensor: 12 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S32_Infos.tensor: 9 Byte items
Loading coefficient file ./BUILD_MODEL_SQ8_EMUL/tensors/S33_Infos.tensor: 9 Byte items
Flash image KWS_ds_cnn_m_quant_L3_Flash_Const.dat (size 142976) for device AT_MEM_L3_HFLASH successfuly generated

Shared L1 Memory size (Bytes)             : Given:      48736, Used:      45492
L2 Memory size (Bytes)                    : Given:     350000, Used:     197153
L3 Memory size (Bytes)                    : Given:    6388608, Used:          0

L3 Memory bandwidth for 1 graph run       :          0 Bytes
L2 Memory bandwidth for 1 graph run       :     499112 Bytes
Sum of all Kernels arguments size         :     408702 Bytes
Tiling Bandwith overhead                  :   1.221213 Move/KerArgSize
Sum of baseline bandwidth                 :   15711780 Bytes
Percentage of baseline BW for L2          :    3.17667 %
Percentage of baseline BW for L3          :          0 %
Sum of all Kernels operations             :    9915296 Operations
Total amount of flash coefficients        :     142976 Bytes

Basic kernels library                     : CNN_BasicKernels_SQ8.h
                                          : KWS_ds_cnn_m_quant.h
Output Directory                          : BUILD_MODEL_SQ8_EMUL

The following files have been generated:
	   KWS_ds_cnn_m_quantKernels.c Generated C code for the user kernels and the user kernels groups
	   KWS_ds_cnn_m_quantKernels.h Header file for the generated C code
	KWS_ds_cnn_m_quant_L3_Flash_Const.dat Flash content for Graph constants
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c main_emulation.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL/main_emulation.d -o BUILD_EMUL/main_emulation.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.d -o BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.d -o BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.d -o BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -c /home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.c -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -MD -MF BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.d -o BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.o
gcc -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -MMD -MP -DMEDIUM -DWITH_MFCC -g -O3 -D__EMUL__ -DAT_INPUT_HEIGHT=49 -DAT_INPUT_WIDTH=10 -DAT_INPUT_COLORS= -I. -I/home/marco-gwt/GWT/AutotilerV2/Emulation -I/home/marco-gwt/GWT/AutotilerV2/Autotiler -I/home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries -I/home/marco-gwt/GWT/AutotilerV2/DSP_Libraries -I/home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8 -IBUILD_MODEL_SQ8_EMUL -I/home/marco-gwt/GWT/gap_sdk/libs/gap_lib/include -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -I/home/marco-gwt/GWT/AutotilerV2/DSP_Generators -I/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL -o kws_ds_cnn_emul  BUILD_EMUL/main_emulation.o  BUILD_EMUL/BUILD_MODEL_SQ8_EMUL/KWS_ds_cnn_m_quantKernels.o  BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/img_io/ImgIO.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/SSD_BasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/Generators/BilinearResizes/ResizeBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries/CNN_CopyBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_AT_Misc.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/math_funcs.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Activation_HWC_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Bias_Linear_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Pooling_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_Conv_DW_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_MatAlgebra_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/CNN_SoftMax_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/CNN_Libraries_SQ8/RNN_SQ8.o  BUILD_EMUL//home/marco-gwt/GWT/gap_sdk/libs/gap_lib/wav_io/wavIO.o  BUILD_EMUL//home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/BUILD_MFCC_MODEL/MFCCKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/TwiddlesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/RFFTTwiddlesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/LUT_Tables/SwapTablesDef.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/MfccBasicKernels.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/FFT_Library.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/CmplxFunctions.o  BUILD_EMUL//home/marco-gwt/GWT/AutotilerV2/DSP_Libraries/PreProcessing.o  -lm
WARNING:tensorflow:From utils/test_accuracy_emul.py:95: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0608 13:46:59.851809 140185943275328 module_wrapper.py:139] From utils/test_accuracy_emul.py:95: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From utils/test_accuracy_emul.py:95: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0608 13:46:59.852335 140185943275328 module_wrapper.py:139] From utils/test_accuracy_emul.py:95: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From utils/test_accuracy_emul.py:96: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.

W0608 13:46:59.852656 140185943275328 module_wrapper.py:139] From utils/test_accuracy_emul.py:96: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.

2021-06-08 13:46:59.853907: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-06-08 13:46:59.862975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2096060000 Hz
2021-06-08 13:46:59.863663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d4bdebce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-06-08 13:46:59.863717: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-06-08 13:46:59.865911: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/marco-gwt/GWT/gap_sdk/install/workstation/lib
2021-06-08 13:46:59.865988: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2021-06-08 13:46:59.866022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist
WARNING:tensorflow:From /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/utils/input_data.py:347: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0608 13:48:39.440713 140185943275328 module_wrapper.py:139] From /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/utils/input_data.py:347: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/utils/input_data.py:348: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0608 13:48:39.442981 140185943275328 module_wrapper.py:139] From /home/marco-gwt/GWT/NN_menu/starters/keyword_spotting/utils/input_data.py:348: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From utils/test_accuracy_emul.py:111: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0608 13:48:39.781874 140185943275328 module_wrapper.py:139] From utils/test_accuracy_emul.py:111: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Validation set size:4445
I0608 13:48:39.782142 140185943275328 test_accuracy_emul.py:111] Validation set size:4445
INFO:tensorflow:Test set size:4890
I0608 13:50:44.848578 140185943275328 test_accuracy_emul.py:157] Test set size:4890
rm: cannot remove 'test.pgm': No such file or directory
make[1]: Leaving directory '/home/marco-gwt/GWT/NN_menu/starters/keyword_spotting'
{'desired_samples': 16000, 'window_size_samples': 640, 'window_stride_samples': 320, 'spectrogram_length': 49, 'dct_coefficient_count': 10, 'fingerprint_width': 10, 'fingerprint_size': 490, 'label_count': 12, 'sample_rate': 16000, 'preprocess': 'mfcc', 'average_window_width': -1, 'use_power': True}
Pred/Tot:	  97/ 100	Accuracy:	97.00%
Pred/Tot:	 197/ 200	Accuracy:	98.50%
Pred/Tot:	 290/ 300	Accuracy:	96.67%
Pred/Tot:	 385/ 400	Accuracy:	96.25%
Pred/Tot:	 480/ 500	Accuracy:	96.00%
Pred/Tot:	 573/ 600	Accuracy:	95.50%
Pred/Tot:	 669/ 700	Accuracy:	95.57%
Pred/Tot:	 761/ 800	Accuracy:	95.12%
Pred/Tot:	 858/ 900	Accuracy:	95.33%
Pred/Tot:	 955/1000	Accuracy:	95.50%
Pred/Tot:	1049/1100	Accuracy:	95.36%
Pred/Tot:	1142/1200	Accuracy:	95.17%
Pred/Tot:	1228/1300	Accuracy:	94.46%
Pred/Tot:	1320/1400	Accuracy:	94.29%
Pred/Tot:	1411/1500	Accuracy:	94.07%
Pred/Tot:	1509/1600	Accuracy:	94.31%
Pred/Tot:	1603/1700	Accuracy:	94.29%
Pred/Tot:	1700/1800	Accuracy:	94.44%
Pred/Tot:	1797/1900	Accuracy:	94.58%
Pred/Tot:	1894/2000	Accuracy:	94.70%
Pred/Tot:	1990/2100	Accuracy:	94.76%
Pred/Tot:	2085/2200	Accuracy:	94.77%
Pred/Tot:	2181/2300	Accuracy:	94.83%
Pred/Tot:	2273/2400	Accuracy:	94.71%
Pred/Tot:	2364/2500	Accuracy:	94.56%
Pred/Tot:	2457/2600	Accuracy:	94.50%
Pred/Tot:	2551/2700	Accuracy:	94.48%
Pred/Tot:	2646/2800	Accuracy:	94.50%
Pred/Tot:	2740/2900	Accuracy:	94.48%
Pred/Tot:	2830/3000	Accuracy:	94.33%
Pred/Tot:	2927/3100	Accuracy:	94.42%
Pred/Tot:	3024/3200	Accuracy:	94.50%
Pred/Tot:	3120/3300	Accuracy:	94.55%
Pred/Tot:	3210/3400	Accuracy:	94.41%
Pred/Tot:	3302/3500	Accuracy:	94.34%
Pred/Tot:	3399/3600	Accuracy:	94.42%
Pred/Tot:	3490/3700	Accuracy:	94.32%
Pred/Tot:	3588/3800	Accuracy:	94.42%
Pred/Tot:	3682/3900	Accuracy:	94.41%
Pred/Tot:	3776/4000	Accuracy:	94.40%
Pred/Tot:	3872/4100	Accuracy:	94.44%
Pred/Tot:	3966/4200	Accuracy:	94.43%
Pred/Tot:	4061/4300	Accuracy:	94.44%
Pred/Tot:	4153/4400	Accuracy:	94.39%

FINAL VALIDATION ACCURACY:
Pred/Tot:	4196/4444	Accuracy:	94.42%

Confusion matrix:
[[371   0   0   0   0   0   0   0   0   0   0   0]
 [  1 333   1   3   4   5   0   7   8   2   3   4]
 [  0   4 388   0   0   2   1   0   0   0   0   2]
 [  0  10   1 380   0   7   1   0   0   0   2   5]
 [  0   2   1   0 327   2   4   0   2   6   6   0]
 [  0   1   0   7   0 360   0   0   0   0   4   5]
 [  0   3   6   1   1   2 336   2   0   0   0   1]
 [  0   9   1   1   0   1   1 349   0   0   0   1]
 [  0   6   0   1   5   1   0   1 343   4   1   1]
 [  0   4   0   0  23   1   3   0   4 335   2   1]
 [  1   2   0   0  10   1   0   0   0   1 334   1]
 [  0   7   0  14   0   6   0   0   1   2   2 340]]
Pred/Tot:	  95/ 100	Accuracy:	95.00%
Pred/Tot:	 190/ 200	Accuracy:	95.00%
Pred/Tot:	 281/ 300	Accuracy:	93.67%
Pred/Tot:	 375/ 400	Accuracy:	93.75%
Pred/Tot:	 468/ 500	Accuracy:	93.60%
Pred/Tot:	 562/ 600	Accuracy:	93.67%
Pred/Tot:	 657/ 700	Accuracy:	93.86%
Pred/Tot:	 751/ 800	Accuracy:	93.88%
Pred/Tot:	 846/ 900	Accuracy:	94.00%
Pred/Tot:	 943/1000	Accuracy:	94.30%
Pred/Tot:	1034/1100	Accuracy:	94.00%
Pred/Tot:	1130/1200	Accuracy:	94.17%
Pred/Tot:	1222/1300	Accuracy:	94.00%
Pred/Tot:	1316/1400	Accuracy:	94.00%
Pred/Tot:	1409/1500	Accuracy:	93.93%
Pred/Tot:	1504/1600	Accuracy:	94.00%
Pred/Tot:	1600/1700	Accuracy:	94.12%
Pred/Tot:	1698/1800	Accuracy:	94.33%
Pred/Tot:	1787/1900	Accuracy:	94.05%
Pred/Tot:	1880/2000	Accuracy:	94.00%
Pred/Tot:	1973/2100	Accuracy:	93.95%
Pred/Tot:	2067/2200	Accuracy:	93.95%
Pred/Tot:	2159/2300	Accuracy:	93.87%
Pred/Tot:	2251/2400	Accuracy:	93.79%
Pred/Tot:	2345/2500	Accuracy:	93.80%
Pred/Tot:	2438/2600	Accuracy:	93.77%
Pred/Tot:	2533/2700	Accuracy:	93.81%
Pred/Tot:	2629/2800	Accuracy:	93.89%
Pred/Tot:	2723/2900	Accuracy:	93.90%
Pred/Tot:	2818/3000	Accuracy:	93.93%
Pred/Tot:	2914/3100	Accuracy:	94.00%
Pred/Tot:	3010/3200	Accuracy:	94.06%
Pred/Tot:	3103/3300	Accuracy:	94.03%
Pred/Tot:	3197/3400	Accuracy:	94.03%
Pred/Tot:	3293/3500	Accuracy:	94.09%
Pred/Tot:	3391/3600	Accuracy:	94.19%
Pred/Tot:	3484/3700	Accuracy:	94.16%
Pred/Tot:	3580/3800	Accuracy:	94.21%
Pred/Tot:	3673/3900	Accuracy:	94.18%
Pred/Tot:	3766/4000	Accuracy:	94.15%
Pred/Tot:	3859/4100	Accuracy:	94.12%
Pred/Tot:	3955/4200	Accuracy:	94.17%
Pred/Tot:	4051/4300	Accuracy:	94.21%
Pred/Tot:	4148/4400	Accuracy:	94.27%
Pred/Tot:	4241/4500	Accuracy:	94.24%
Pred/Tot:	4329/4600	Accuracy:	94.11%
Pred/Tot:	4423/4700	Accuracy:	94.11%
Pred/Tot:	4516/4800	Accuracy:	94.08%

FINAL TESTING ACCURACY:
Pred/Tot:	4601/4889	Accuracy:	94.11%

Confusion matrix:
[[408   0   0   0   0   0   0   0   0   0   0   0]
 [  0 382   0   3   3   5   3   3   4   2   2   1]
 [  0   7 406   4   0   1   1   0   0   0   0   0]
 [  0   5   0 389   2   3   1   0   0   1   0   4]
 [  0   6   0   0 400   3   0   0   4   7   4   1]
 [  0   5   1  14   0 373   1   0   2   0   1   9]
 [  0   7   6   1   0   0 397   1   0   0   0   0]
 [  0  14   0   0   0   3   6 370   1   0   1   1]
 [  0   7   0   0   3   9   0   0 363  12   1   1]
 [  0   9   0   1  13   1   0   0   5 368   2   3]
 [  0   5   1   0   6   5   0   0   1   2 387   4]
 [  0   9   0  26   1   2   0   2   1   1   2 358]]
